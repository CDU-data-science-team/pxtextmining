# pxtextmining API

To facilitate the use of the models trained in this project, an API has been created using the FastAPI library. Users will be able to send their patient experience feedback comments to the model via the API, and will receive the predicted labels for those comments.

The API has been created using FastAPI and will be deployed on RStudio Connect. The URL is not publicly available at this stage in the project. Full documentation for the API, automatically generated by FastAPI, is available at [API URL]/docs

## How to make an API call

1\. Prepare the data in JSON format. In Python, this is a `list` containing as many `dict`s as there are comments to be predicted. Each `dict` has three compulsory keys:

  * `comment_id`: Unique ID associated with the comment, in `str` format. Each Comment ID per API call must be unique.
  * `comment_text`: Text to be classified, in `str` format.
  * `question_type`: The type of question asked to elicit the comment text. Questions are different from trust to trust, but they all fall into one of three categories:
       * `what_good`: Any variation on the question "What was good about the service?", or "What did we do well?"
       * `could_improve`: Any variation on the question "Please tell us about anything that we could have done better", or "How could we improve?"
       * `nonspecific`: Any other type of nonspecific question, e.g. "Please can you tell us why you gave your answer?", or "What were you satisfied and/or dissatisfied with?".

```python
# In Python

text_data = [
              { 'comment_id': '1', # The comment_id values in each dict must be unique.
                'comment_text': 'This is the first comment. Nurse was great.',
                'question_type': 'what_good' },
              { 'comment_id': '2',
                'comment_text': 'This is the second comment. The ward was freezing.',
                'question_type': 'could_improve' },
              { 'comment_id': '3',
                'comment_text': '',  # This comment is an empty string.
                'question_type': 'nonspecific' }
            ]
```

```R
# In R

library(jsonlite)

comment_id <- c("1", "2", "3")
comment_text <- c(
  "This is the first comment. Nurse was great.",
  "This is the second comment. The ward was freezing.",
  ""
)
question_type <- c("what_good", "could_improve", "nonspecific")
df <- data.frame(comment_id, comment_text, question_type)
text_data <- toJSON(df)
```


2\. Send the JSON containing the text data to the `predict_multilabel` endpoint. In python, this can be done using the `requests` library.

```python
# In Python

import requests

url = "API_URL_GOES_HERE"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'}

response = requests.post(f"{url}/predict_multilabel",
                          json = text_data, headers = headers)
```

```R
# In R

library(httr)

r <- POST(
  url = "API_URL_GOES_HERE",
  body = text_data,
  encode = "json",
  add_headers(
    "User-Agent" = "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36",
    "Content-Type" = "application/json"
  )
)
```

3\. After waiting for the data to be processed and passed through the machine learning model, receive predicted labels at the same endpoint, in the example format below. Note that the comment with blank text, with comment_id 3, was assigned the label 'Labelling not possible' as it would have been stripped out during preprocessing.

```python
# In Python

print(response.json())
# Output below
[
  { 'comment_id': '1',
    'comment_text': 'This is the first comment. Nurse was great.',
    'labels': ['Non-specific praise for staff']} ,
  { 'comment_id': '2',
    'comment_text': 'This is the second comment. The ward was freezing.',
    'labels': ['Sensory experience']} ,
  { 'comment_id': '3',
    'comment_text': '',
    'labels': ['Labelling not possible'] }
]
```

```R
# In R

content(r, "text")
```
