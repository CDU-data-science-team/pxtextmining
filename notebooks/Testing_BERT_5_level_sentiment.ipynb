{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96e6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2022/04/building-state-of-the-art-text-classifier-using-huggingface-and-tensorflow/\n",
    "# https://www.kaggle.com/code/satyampd/bert-text-classification-w-keras-huggingface/notebook\n",
    "# https://huggingface.co/course/chapter3/3?fw=tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922f95ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ea35b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>label</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>feedback</th>\n",
       "      <th>criticality</th>\n",
       "      <th>organization</th>\n",
       "      <th>question</th>\n",
       "      <th>row_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xn</td>\n",
       "      <td>Couldn't be improved</td>\n",
       "      <td>Nothing to improve</td>\n",
       "      <td>Nothing.</td>\n",
       "      <td>3</td>\n",
       "      <td>Trust A</td>\n",
       "      <td>Trust A - Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee</td>\n",
       "      <td>Environment/ facilities</td>\n",
       "      <td>Environment/ facilities</td>\n",
       "      <td>Temperature in theatre a little low.</td>\n",
       "      <td>-1</td>\n",
       "      <td>Trust A</td>\n",
       "      <td>Trust A - Q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ap</td>\n",
       "      <td>Access</td>\n",
       "      <td>Provision of services</td>\n",
       "      <td>Same service available at Bingham Health Centre.</td>\n",
       "      <td>-2</td>\n",
       "      <td>Trust A</td>\n",
       "      <td>Trust A - Q1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mi</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Amount/clarity of information</td>\n",
       "      <td>Appointment details given over phone - no phys...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Trust A</td>\n",
       "      <td>Trust A - Q1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mm</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Communication</td>\n",
       "      <td>On one occasion I was not made aware that my a...</td>\n",
       "      <td>-3</td>\n",
       "      <td>Trust A</td>\n",
       "      <td>Trust A - Q1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                    label                    subcategory  \\\n",
       "0   xn     Couldn't be improved             Nothing to improve   \n",
       "1   ee  Environment/ facilities        Environment/ facilities   \n",
       "2   ap                   Access          Provision of services   \n",
       "3   mi            Communication  Amount/clarity of information   \n",
       "4   mm            Communication                  Communication   \n",
       "\n",
       "                                            feedback criticality organization  \\\n",
       "0                                           Nothing.           3      Trust A   \n",
       "1               Temperature in theatre a little low.          -1      Trust A   \n",
       "2   Same service available at Bingham Health Centre.          -2      Trust A   \n",
       "3  Appointment details given over phone - no phys...          -1      Trust A   \n",
       "4  On one occasion I was not made aware that my a...          -3      Trust A   \n",
       "\n",
       "       question  row_index  \n",
       "0  Trust A - Q1          0  \n",
       "1  Trust A - Q1          1  \n",
       "2  Trust A - Q1          2  \n",
       "3  Trust A - Q1          3  \n",
       "4  Trust A - Q1          4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/text_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033a958f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10334, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24b29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'-5': 0,\n",
    " '-4': 0,\n",
    " '-3': 1,\n",
    " '-2': 1,\n",
    " '-1': 1,\n",
    " '0': 2,\n",
    " '1': 3,\n",
    " '2': 3,\n",
    " '3': 3,\n",
    " '4': 4,\n",
    " '5': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929bfb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    5025\n",
       "2.0    2566\n",
       "1.0    1630\n",
       "4.0     882\n",
       "0.0     195\n",
       "Name: sentiment_categories, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment_categories'] = data['criticality'].map(values)\n",
    "data['sentiment_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce320ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = data[['feedback', 'sentiment_categories']].dropna()\n",
    "x = text_data[['feedback']].rename(columns = {'feedback':'predictor'})\n",
    "y = text_data['sentiment_categories'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c453e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_train, x_test, y_train, y_test, index_training_data, index_test_data  = train_test_split(x, y, pd.DataFrame(x).index,\n",
    "#                                                                                              test_size=0.3,\n",
    "#                                                                                              stratify=y,\n",
    "#                                                                                              shuffle=True\n",
    "#                                                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f125c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_ckpt, truncation=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d0cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10297/10297 [00:01<00:00, 6300.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example, truncation=True, max_length=100)\n",
    "\n",
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in tqdm(x['predictor']):\n",
    "    bert_inp=tokenizer.encode_plus(sent,add_special_tokens = True, truncation = True, padding = 'max_length',  max_length =128,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "target = np.array(pd.get_dummies(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0b5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test,train_mask,test_mask=train_test_split(input_ids,target,attention_masks,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42750674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,486,085\n",
      "Trainable params: 109,486,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa43d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "num_epochs = 6\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_train_steps = len(X_train) * num_epochs\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "opt = Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "es = EarlyStopping(patience = 1, restore_best_weights=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3e3d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "206/206 [==============================] - 3747s 18s/step - loss: 0.8318 - accuracy: 0.6763 - val_loss: 0.6248 - val_accuracy: 0.7488\n",
      "Epoch 2/5\n",
      "206/206 [==============================] - 3546s 17s/step - loss: 0.5167 - accuracy: 0.7941 - val_loss: 0.6069 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "206/206 [==============================] - 3499s 17s/step - loss: 0.3230 - accuracy: 0.8780 - val_loss: 0.7168 - val_accuracy: 0.7627\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([X_train,train_mask],y_train,batch_size=32,epochs=5,validation_split = 0.2 , callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc01c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 421). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BERT_5_level_sentiment/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: BERT_5_level_sentiment/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('BERT_5_level_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa543957",
   "metadata": {},
   "source": [
    "## No good. should have used tf.data.Dataset to create my dataset 22/11/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73eb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
