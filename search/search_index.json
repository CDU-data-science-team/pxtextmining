{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home This site contains the project documentation for the pxtextmining python package. Table Of Contents The documentation is split into three separate sections: Project background Getting started, a simple approach to using the package: Installation Training a new model Making predictions with a trained model Code reference, a more technical overview of the functions and modules: Factories Helpers Pipelines","title":"Home"},{"location":"#home","text":"This site contains the project documentation for the pxtextmining python package.","title":"Home"},{"location":"#table-of-contents","text":"The documentation is split into three separate sections: Project background Getting started, a simple approach to using the package: Installation Training a new model Making predictions with a trained model Code reference, a more technical overview of the functions and modules: Factories Helpers Pipelines","title":"Table Of Contents"},{"location":"about/","text":"Project background The pxtextmining project is hosted by Nottinghamshire Healthcare NHS Foundation Trust's Clinical Development Unit Data Science Team, and funded by NHS England's Insight and Feedback Team. The primary objective of the project is to create a machine learning model capable of analysing and categorising the free text data obtained through the NHS England Friends and Family Test (FFT). In doing so, it will support better use of qualitative patient experience feedback by NHS provider organisations. This package works together with the experiencesdashboard , a frontend coded in R/Shiny. Joint documentation for the project as a whole is forthcoming.","title":"Project background"},{"location":"about/#project-background","text":"The pxtextmining project is hosted by Nottinghamshire Healthcare NHS Foundation Trust's Clinical Development Unit Data Science Team, and funded by NHS England's Insight and Feedback Team. The primary objective of the project is to create a machine learning model capable of analysing and categorising the free text data obtained through the NHS England Friends and Family Test (FFT). In doing so, it will support better use of qualitative patient experience feedback by NHS provider organisations. This package works together with the experiencesdashboard , a frontend coded in R/Shiny. Joint documentation for the project as a whole is forthcoming.","title":"Project background"},{"location":"getting%20started/install/","text":"Installation You can install pxtextmining from either PyPI or GitHub . Optional: create a Python Virtual Environment in which to install pxtextmining and its dependencies. This will allow you to keep the package versions required by the package separate from any others that you may have installed. Let's call the virtual environment text_venv : Manually creating virtual environment 1. Open a terminal, navigate to the folder where you want to put the virtual environment and run: - python3 -m venv text_venv (Linux & MacOS); - python -m venv text_venv (Windows); 2. Activate the virtual environment. In the folder containing folder text_venv run: - source text_venv/bin/activate (Linux & MacOS); - text_venv\\Scripts\\activate (Windows); Using pyenv to create the virtual environment If you have pyenv installed: Run pyenv virtualenv text_venv to create the new virtual environment. Activate it with pyenv activate text_venv Option 1: Install from PyPI This option allows you to use the functions coded in pxtextmining. Install pxtextmining and its PyPI dependencies: pip3 install pxtextmining (Linux & MacOS); pip install pxtextmining (Windows); We also need to install a couple of spaCy models. python -m spacy download en_core_web_sm python -m spacy download en_core_web_lg Note that the second model is pretty large, so the installation may take a while. Option 2: Install from GitHub This option is recommended as it gives you access to the full datasets and already trained models. To begin with, clone the repository from github. Navigate to the repository folder on your computer. run pip install . We also need to install a couple of spaCy models. python -m spacy download en_core_web_sm python -m spacy download en_core_web_lg Note that the second model is pretty large, so the installation may take a while.","title":"Install"},{"location":"getting%20started/install/#installation","text":"You can install pxtextmining from either PyPI or GitHub .","title":"Installation"},{"location":"getting%20started/install/#optional-create-a-python-virtual-environment-in-which-to-install-pxtextmining-and-its-dependencies","text":"This will allow you to keep the package versions required by the package separate from any others that you may have installed. Let's call the virtual environment text_venv : Manually creating virtual environment 1. Open a terminal, navigate to the folder where you want to put the virtual environment and run: - python3 -m venv text_venv (Linux & MacOS); - python -m venv text_venv (Windows); 2. Activate the virtual environment. In the folder containing folder text_venv run: - source text_venv/bin/activate (Linux & MacOS); - text_venv\\Scripts\\activate (Windows); Using pyenv to create the virtual environment If you have pyenv installed: Run pyenv virtualenv text_venv to create the new virtual environment. Activate it with pyenv activate text_venv","title":"Optional: create a Python Virtual Environment in which to install pxtextmining and its dependencies."},{"location":"getting%20started/install/#option-1-install-from-pypi","text":"This option allows you to use the functions coded in pxtextmining. Install pxtextmining and its PyPI dependencies: pip3 install pxtextmining (Linux & MacOS); pip install pxtextmining (Windows); We also need to install a couple of spaCy models. python -m spacy download en_core_web_sm python -m spacy download en_core_web_lg Note that the second model is pretty large, so the installation may take a while.","title":"Option 1: Install from PyPI"},{"location":"getting%20started/install/#option-2-install-from-github","text":"This option is recommended as it gives you access to the full datasets and already trained models. To begin with, clone the repository from github. Navigate to the repository folder on your computer. run pip install . We also need to install a couple of spaCy models. python -m spacy download en_core_web_sm python -m spacy download en_core_web_lg Note that the second model is pretty large, so the installation may take a while.","title":"Option 2: Install from GitHub"},{"location":"getting%20started/training_new_model/","text":"Training a new model To train a new model to categorise patient feedback text, labelled data is required. Data from phase 1 of the project is available in the folder datasets , or it can also be loaded from an SQL database. If you have your own labelled patient experience feedback, you can use this instead to train your own model. The text_classification_pipeline contains the function required to output a fully trained model. Two types of models can be trained using this pipeline, one that can predict the categorical 'label' for the text, or one that can predict the positive or negative 'criticality' score for the text. Examples of the pipeline being used to output each type of model can be seen in execution_criticality and execution_label . The steps involved in training a model are as follows: The data is loaded and split into training and test sets by the function factory_data_load_and_split . This also conducts some basic text preprocessing, such as removing special characters, whitespaces and linebreaks. It produces additional features through the creation of 'text_length' and sentiment scores using vaderSentiment and textblob . Any invalid lines (e.g. empty strings, NULL values) are removed from the data. The function in factory_pipeline creates an sklearn pipeline. This pipeline is comprised of the following steps: first, the preprocessed text input is upsampled to help compensate for the unbalanced dataset. The text is then tokenized and vectorised (turned into numbers that can be processed by the model) using either spacy or wordnet . Feature selection is then conducted to select only the most important features to train the model. A hyperparameter grid is constructed with potential hyperparameter values, depending on the learners/classification models to be tested in the Randomized Search. A Randomized Search is then used to identify the best performing model and its optimal hyperparameters. The fitted pipeline is then evaluated on the test set in factory_model_performance . The evaluation metrics used are: ( Accuracy , Class Balance Accuracy (Mosley, 2013), Balanced Accuracy (Guyon et al., 2015, Kelleher et al., 2015) and Matthews Correlation Coefficient (Baldi et al., 2000, Matthews, 1975)). A visual representation of the performance evaluation is output in the form of a barchart. Writing the results: The fitted pipeline, tuning results, predictions, accuracy per class, model comparison barchart, training data index, and test data index are output by factory_write_results . The four steps above are all pulled together in pxtextmining.pipelines.text_classification_pipeline . Here is a visual display of the process:","title":"Training a new model"},{"location":"getting%20started/training_new_model/#training-a-new-model","text":"To train a new model to categorise patient feedback text, labelled data is required. Data from phase 1 of the project is available in the folder datasets , or it can also be loaded from an SQL database. If you have your own labelled patient experience feedback, you can use this instead to train your own model. The text_classification_pipeline contains the function required to output a fully trained model. Two types of models can be trained using this pipeline, one that can predict the categorical 'label' for the text, or one that can predict the positive or negative 'criticality' score for the text. Examples of the pipeline being used to output each type of model can be seen in execution_criticality and execution_label . The steps involved in training a model are as follows: The data is loaded and split into training and test sets by the function factory_data_load_and_split . This also conducts some basic text preprocessing, such as removing special characters, whitespaces and linebreaks. It produces additional features through the creation of 'text_length' and sentiment scores using vaderSentiment and textblob . Any invalid lines (e.g. empty strings, NULL values) are removed from the data. The function in factory_pipeline creates an sklearn pipeline. This pipeline is comprised of the following steps: first, the preprocessed text input is upsampled to help compensate for the unbalanced dataset. The text is then tokenized and vectorised (turned into numbers that can be processed by the model) using either spacy or wordnet . Feature selection is then conducted to select only the most important features to train the model. A hyperparameter grid is constructed with potential hyperparameter values, depending on the learners/classification models to be tested in the Randomized Search. A Randomized Search is then used to identify the best performing model and its optimal hyperparameters. The fitted pipeline is then evaluated on the test set in factory_model_performance . The evaluation metrics used are: ( Accuracy , Class Balance Accuracy (Mosley, 2013), Balanced Accuracy (Guyon et al., 2015, Kelleher et al., 2015) and Matthews Correlation Coefficient (Baldi et al., 2000, Matthews, 1975)). A visual representation of the performance evaluation is output in the form of a barchart. Writing the results: The fitted pipeline, tuning results, predictions, accuracy per class, model comparison barchart, training data index, and test data index are output by factory_write_results . The four steps above are all pulled together in pxtextmining.pipelines.text_classification_pipeline . Here is a visual display of the process:","title":"Training a new model"},{"location":"getting%20started/using_trained_model/","text":"Using a trained model The results folders (e.g. results_label ) always contain a fully trained model in .sav format, as well as performance metrics for the model. The models saved here are used to make predictions on the experiencesdashboard frontend. To use one of these pretrained models to make predictions: Prepare a pandas DataFrame of the text you want to classify. Preprocess the text using the pxtextmining.factories.factory_data_load_and_split.clean_data function, specifying target=False Use this dataframe as the dataset argument in factory_predict_unlabelled_text . An example of these steps in action is available in execution_predict . Be wary of preparing your dataset using Excel , as it can cause issues due to text encoding errors. LibreOffice is a good alternative.","title":"Using a trained model"},{"location":"getting%20started/using_trained_model/#using-a-trained-model","text":"The results folders (e.g. results_label ) always contain a fully trained model in .sav format, as well as performance metrics for the model. The models saved here are used to make predictions on the experiencesdashboard frontend. To use one of these pretrained models to make predictions: Prepare a pandas DataFrame of the text you want to classify. Preprocess the text using the pxtextmining.factories.factory_data_load_and_split.clean_data function, specifying target=False Use this dataframe as the dataset argument in factory_predict_unlabelled_text . An example of these steps in action is available in execution_predict . Be wary of preparing your dataset using Excel , as it can cause issues due to text encoding errors. LibreOffice is a good alternative.","title":"Using a trained model"},{"location":"reference/factories/factory_data_load_and_split/","text":"factory_data_load_and_split load_data(filename, target, predictor, theme=None) This function loads the data from a csv, dataframe, or SQL database. It returns a pd.DataFrame with the data required for training a machine learning model. Parameters: Name Type Description Default filename pd.DataFrame A pandas.DataFrame with the data (class and text columns), otherwise the dataset name (CSV), including full path to the data folder (if not in the project's working directory), and the data type suffix (\".csv\"). If filename is None , the data is read from the SQL database. NOTE: The feature that reads data from the database is for internal use only. Experienced users who would like to pull their data from their own databases can, of course, achieve that by slightly modifying the relevant lines in the script and setting up the connection to the SQL server. required target str Name of the column containing the target to be predicted. required predictor str Name of the column containing the text to be used to train the model or make predictions. required theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality' None Returns: Type Description pandas.DataFrame a pandas.DataFrame with the columns named in a way that works for the rest of the pipeline remove_punc_and_nums(text) This function removes excess punctuation and numbers from the text. Exclamation marks and apostrophes have been left in, as have words in allcaps, as these may denote strong sentiment. Returns a string. Parameters: Name Type Description Default text str Text to be cleaned required Returns: Type Description str the cleaned text as a str clean_data(text_data, target=False) Function to clean and preprocess data, for training a model or for making predictions using a trained model. target = True if processing labelled data for training a model. The DataFrame should contain a column named 'predictor' containing the text to be processed. If processing dataset with no target, i.e. to make predictions using unlabelled data, then target = False. This function also drops NaNs. Parameters: Name Type Description Default text_data pd.DataFrame A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required target str, optional A string. If present, then it denotes that the dataset is for training a model and the y 'target' column is present in the dataframe. If set to False, then the function is able to clean text data in the 'predictor' column for making new predictions using a trained model. False Returns: Type Description pandas.DataFrame a pandas.DataFrame with the 'predictor' column cleaned reduce_crit(text_data, theme) 'Criticality' is an indication of how strongly negative or positive a comment is. A comment with a criticality value of '-5' is very strongly critical of the organisation. A comment with a criticality value of '3' is mildly positive about the organisation. 'Criticality' labels are specific to data collected by Nottinghamshire Healthcare NHS Foundation Trust. This function manipulates the criticality levels to account for an imbalanced dataset. There are not enough samples belonging to classes '-5' and '5' so these are set to '-4' and '4'. This function also sets the 'criticality' value for all comments tagged as 'Couldn't be improved' to '3'. Parameters: Name Type Description Default text_data pd.DataFrame A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality' required Returns: Type Description pandas.DataFrame a pandas.DataFrame with the ordinal values in the 'target' column changed from 5 to 4, or -5 to -4. process_data(text_data, target=False) Function to clean data and add feature engineering including sentiment scores and text length. target = True if processing labelled data for training a model. If processing dataset with no target, i.e. to make predictions using unlabelled data, then target = False. Parameters: Name Type Description Default text_data pd.DataFrame, A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required target str, optional Name of the column containing the target to be predicted. False Returns: Type Description pandas.DataFrame a pandas.DataFrame with the ordinal values in the 'target' column changed from 5 to 4, or -5 to -4. factory_data_load_and_split(filename, target, predictor, test_size=0.33, reduce_criticality=False, theme=None) This function pulls together all the functions above. It loads the dataset, renames the response and predictor as \"target\" and \"predictor\" respectively, conducts preprocessing, and splits the dataset into training and test sets. NOTE: As described later, arguments reduce_criticality and theme are for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) and criticality labels. They can otherwise be safely ignored. Parameters: Name Type Description Default filename pd.DataFrame A pandas.DataFrame with the data (class and text columns), otherwise the dataset name (CSV), including full path to the data folder (if not in the project's working directory), and the data type suffix (\".csv\"). If filename is None , the data is read from the SQL database. NOTE: The feature that reads data from the database is for internal use only. Experienced users who would like to pull their data from their own databases can, of course, achieve that by slightly modifying the relevant lines in the script and setting up the connection to the SQL server. required target str Name of the column containing the target to be predicted. required predictor str Name of the column containing the text to be used to train the model or make predictions. required test_size float, optional Proportion of data that will form the test dataset. 0.33 reduce_criticality bool, optional For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that hold data on criticality. If True , then all records with a criticality of \"-5\" (respectively, \"5\") are assigned a criticality of \"-4\" (respectively, \"4\"). This is to avoid situations where the pipeline breaks due to a lack of sufficient data for \"-5\" and/or \"5\". This param is only relevant when target = \"criticality\" False theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality'. If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description tuple A tuple containing the following objects in order: x_train, a pd.DataFrame containing the training data; x_test, a pd.DataFrame containing the test data; y_train, a pd.Series containing the targets for the training data; y_test, a pd.Series containing the targets for the test data; index_training_data, a pd.Series of the indices of the data used in the train set; index_test_data, a pd.Series of the indices of the data used in the test set","title":"Factory data load and split"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split","text":"","title":"factory_data_load_and_split"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.load_data","text":"This function loads the data from a csv, dataframe, or SQL database. It returns a pd.DataFrame with the data required for training a machine learning model. Parameters: Name Type Description Default filename pd.DataFrame A pandas.DataFrame with the data (class and text columns), otherwise the dataset name (CSV), including full path to the data folder (if not in the project's working directory), and the data type suffix (\".csv\"). If filename is None , the data is read from the SQL database. NOTE: The feature that reads data from the database is for internal use only. Experienced users who would like to pull their data from their own databases can, of course, achieve that by slightly modifying the relevant lines in the script and setting up the connection to the SQL server. required target str Name of the column containing the target to be predicted. required predictor str Name of the column containing the text to be used to train the model or make predictions. required theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality' None Returns: Type Description pandas.DataFrame a pandas.DataFrame with the columns named in a way that works for the rest of the pipeline","title":"load_data()"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.remove_punc_and_nums","text":"This function removes excess punctuation and numbers from the text. Exclamation marks and apostrophes have been left in, as have words in allcaps, as these may denote strong sentiment. Returns a string. Parameters: Name Type Description Default text str Text to be cleaned required Returns: Type Description str the cleaned text as a str","title":"remove_punc_and_nums()"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.clean_data","text":"Function to clean and preprocess data, for training a model or for making predictions using a trained model. target = True if processing labelled data for training a model. The DataFrame should contain a column named 'predictor' containing the text to be processed. If processing dataset with no target, i.e. to make predictions using unlabelled data, then target = False. This function also drops NaNs. Parameters: Name Type Description Default text_data pd.DataFrame A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required target str, optional A string. If present, then it denotes that the dataset is for training a model and the y 'target' column is present in the dataframe. If set to False, then the function is able to clean text data in the 'predictor' column for making new predictions using a trained model. False Returns: Type Description pandas.DataFrame a pandas.DataFrame with the 'predictor' column cleaned","title":"clean_data()"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.reduce_crit","text":"'Criticality' is an indication of how strongly negative or positive a comment is. A comment with a criticality value of '-5' is very strongly critical of the organisation. A comment with a criticality value of '3' is mildly positive about the organisation. 'Criticality' labels are specific to data collected by Nottinghamshire Healthcare NHS Foundation Trust. This function manipulates the criticality levels to account for an imbalanced dataset. There are not enough samples belonging to classes '-5' and '5' so these are set to '-4' and '4'. This function also sets the 'criticality' value for all comments tagged as 'Couldn't be improved' to '3'. Parameters: Name Type Description Default text_data pd.DataFrame A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality' required Returns: Type Description pandas.DataFrame a pandas.DataFrame with the ordinal values in the 'target' column changed from 5 to 4, or -5 to -4.","title":"reduce_crit()"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.process_data","text":"Function to clean data and add feature engineering including sentiment scores and text length. target = True if processing labelled data for training a model. If processing dataset with no target, i.e. to make predictions using unlabelled data, then target = False. Parameters: Name Type Description Default text_data pd.DataFrame, A pandas.DataFrame with the data to be cleaned. Essential to have one column labelled 'predictor', containing text for training or predictions. required target str, optional Name of the column containing the target to be predicted. False Returns: Type Description pandas.DataFrame a pandas.DataFrame with the ordinal values in the 'target' column changed from 5 to 4, or -5 to -4.","title":"process_data()"},{"location":"reference/factories/factory_data_load_and_split/#pxtextmining.factories.factory_data_load_and_split.factory_data_load_and_split","text":"This function pulls together all the functions above. It loads the dataset, renames the response and predictor as \"target\" and \"predictor\" respectively, conducts preprocessing, and splits the dataset into training and test sets. NOTE: As described later, arguments reduce_criticality and theme are for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) and criticality labels. They can otherwise be safely ignored. Parameters: Name Type Description Default filename pd.DataFrame A pandas.DataFrame with the data (class and text columns), otherwise the dataset name (CSV), including full path to the data folder (if not in the project's working directory), and the data type suffix (\".csv\"). If filename is None , the data is read from the SQL database. NOTE: The feature that reads data from the database is for internal use only. Experienced users who would like to pull their data from their own databases can, of course, achieve that by slightly modifying the relevant lines in the script and setting up the connection to the SQL server. required target str Name of the column containing the target to be predicted. required predictor str Name of the column containing the text to be used to train the model or make predictions. required test_size float, optional Proportion of data that will form the test dataset. 0.33 reduce_criticality bool, optional For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that hold data on criticality. If True , then all records with a criticality of \"-5\" (respectively, \"5\") are assigned a criticality of \"-4\" (respectively, \"4\"). This is to avoid situations where the pipeline breaks due to a lack of sufficient data for \"-5\" and/or \"5\". This param is only relevant when target = \"criticality\" False theme str, optional Name of the column containing the 'theme' data which can be used to train a model predicting 'criticality'. If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description tuple A tuple containing the following objects in order: x_train, a pd.DataFrame containing the training data; x_test, a pd.DataFrame containing the test data; y_train, a pd.Series containing the targets for the training data; y_test, a pd.Series containing the targets for the test data; index_training_data, a pd.Series of the indices of the data used in the train set; index_test_data, a pd.Series of the indices of the data used in the test set","title":"factory_data_load_and_split()"},{"location":"reference/factories/factory_model_performance/","text":"factory_model_performance get_metrics(x_train, x_test, y_train, y_test, model=None) Function to produce performance metrics for a specific machine learning model. Parameters: Name Type Description Default x_train pd.DataFrame Training data (predictor). required y_train pd.Series Training data (target). required x_test pd.DataFrame Test data (predictor). required y_test pd.Series Test data (target). required model str Trained classifier. Defaults to 'dummy' which instantiates dummy classifier for baseline metrics. None Returns: Type Description tuple A tuple containing the following objects, in order: A python dict containing the performance metrics 'accuracy', 'balanced accuracy', 'class balance accuracy', and 'matthews correlation coefficient'; A pd.Series containing the predicted values for x_test, produced by the model. get_accuracy_per_class(y_test, pred) Function to produce accuracy per class for the predicted categories, compared against real values. Parameters: Name Type Description Default y_test pd.Series Test data (real target values). required pred pd.Series Predicted target values. required Returns: Type Description pd.DataFrame The computed accuracy per class metrics for the model. factory_model_performance(pipe, x_train, y_train, x_test, y_test, metric='class_balance_accuracy_score') Evaluate the performance of a fitted pipeline. Parameters: Name Type Description Default pipe sklearn.pipeline.Pipeline Fitted [sklearn.pipeline.Pipeline] (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) required x_train pd.DataFrame Training data (predictor). required y_train pd.Series Training data (target). required x_test pd.DataFrame Test data (predictor). required y_test pd.Series Test data (target). required metric str Performance metrics (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' Returns: Type Description tuple A tuple containing the following objects, in order: The fitted Scikit-learn/imblearn pipeline; A pandas.DataFrame with all (hyper)parameter values and models tried during fitting; A pandas.DataFrame with the predictions on the test set; A pandas.DataFrame with accuracies per class; A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner; A dict containing performance metrics and model metadata.","title":"Factory model performance"},{"location":"reference/factories/factory_model_performance/#pxtextmining.factories.factory_model_performance","text":"","title":"factory_model_performance"},{"location":"reference/factories/factory_model_performance/#pxtextmining.factories.factory_model_performance.get_metrics","text":"Function to produce performance metrics for a specific machine learning model. Parameters: Name Type Description Default x_train pd.DataFrame Training data (predictor). required y_train pd.Series Training data (target). required x_test pd.DataFrame Test data (predictor). required y_test pd.Series Test data (target). required model str Trained classifier. Defaults to 'dummy' which instantiates dummy classifier for baseline metrics. None Returns: Type Description tuple A tuple containing the following objects, in order: A python dict containing the performance metrics 'accuracy', 'balanced accuracy', 'class balance accuracy', and 'matthews correlation coefficient'; A pd.Series containing the predicted values for x_test, produced by the model.","title":"get_metrics()"},{"location":"reference/factories/factory_model_performance/#pxtextmining.factories.factory_model_performance.get_accuracy_per_class","text":"Function to produce accuracy per class for the predicted categories, compared against real values. Parameters: Name Type Description Default y_test pd.Series Test data (real target values). required pred pd.Series Predicted target values. required Returns: Type Description pd.DataFrame The computed accuracy per class metrics for the model.","title":"get_accuracy_per_class()"},{"location":"reference/factories/factory_model_performance/#pxtextmining.factories.factory_model_performance.factory_model_performance","text":"Evaluate the performance of a fitted pipeline. Parameters: Name Type Description Default pipe sklearn.pipeline.Pipeline Fitted [sklearn.pipeline.Pipeline] (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) required x_train pd.DataFrame Training data (predictor). required y_train pd.Series Training data (target). required x_test pd.DataFrame Test data (predictor). required y_test pd.Series Test data (target). required metric str Performance metrics (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' Returns: Type Description tuple A tuple containing the following objects, in order: The fitted Scikit-learn/imblearn pipeline; A pandas.DataFrame with all (hyper)parameter values and models tried during fitting; A pandas.DataFrame with the predictions on the test set; A pandas.DataFrame with accuracies per class; A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner; A dict containing performance metrics and model metadata.","title":"factory_model_performance()"},{"location":"reference/factories/factory_pipeline/","text":"factory_pipeline factory_pipeline(x, y, tknz='spacy', ordinal=False, metric='class_balance_accuracy_score', cv=5, n_iter=100, n_jobs=5, verbose=1, learners=['SGDClassifier', 'RidgeClassifier', 'Perceptron', 'PassiveAggressiveClassifier', 'BernoulliNB', 'ComplementNB', 'MultinomialNB', 'RandomForestClassifier'], theme=None) Prepare and fit a text classification pipeline. The pipeline is then fitted using Randomized Search to identify the best performing model and hyperparameters. Feature engineering: Converts text into TF-IDFs or GloVe word vectors with spaCy ; Applies sklearn.preprocessing.KBinsDiscretizer to the text length and sentiment indicator features, and sklearn.preprocessing.StandardScaler to the embeddings (word vectors); Up-sampling of rare classes: uses imblearn.over_sampling.RandomOverSampler to up-sample rare classes Tokenization and lemmatization of the text feature: uses spaCy (default) or NLTK Feature selection: Uses sklearn.feature_selection.SelectPercentile with sklearn.feature_selection.chi2 for TF-IDFs or sklearn.feature_selection.f_classif for embeddings. Fitting and benchmarking of user-supplied Scikit-learn classifiers A param_grid containing a range of hyperparameters to test is created depending on the tokenizer and the learners chosen. The values in the grid are currently lists/tuples of values that are defined either empirically or are based on the published literature (e.g. for Random Forest, see Probst et al. 2019 . Values may be replaced by appropriate distributions in a future release. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default ordinal bool Whether to fit an ordinal classification model. The ordinal model is the implementation of Frank and Hall (2001) that can use any standard classification model that calculates probabilities. False x pd.DataFrame The text feature. required y pd.Series The response variable (target). required tknz str Tokenizer to use (\"spacy\" or \"wordnet\"). 'spacy' metric str Scorer to use during pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' cv int Number of cross-validation folds. 5 n_iter int Number of parameter settings that are sampled in the RandomizedSearch. 100 n_jobs int Number of jobs to run in parallel in the RandomizedSearch. 5 verbose int Controls the verbosity in the RandomizedSearch. 1 learners list A list of Scikit-learn names of the learners to tune. Must be one or more of \"SGDClassifier\", \"RidgeClassifier\", \"Perceptron\", \"PassiveAggressiveClassifier\", \"BernoulliNB\", \"ComplementNB\", \"MultinomialNB\", \"KNeighborsClassifier\", \"NearestCentroid\", \"RandomForestClassifier\". When a single model is used, it can be passed as a string. ['SGDClassifier', 'RidgeClassifier', 'Perceptron', 'PassiveAggressiveClassifier', 'BernoulliNB', 'ComplementNB', 'MultinomialNB', 'RandomForestClassifier'] theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description sklearn.pipeline.Pipeline A tuned sklearn.pipeline.Pipeline","title":"Factory pipeline"},{"location":"reference/factories/factory_pipeline/#pxtextmining.factories.factory_pipeline","text":"","title":"factory_pipeline"},{"location":"reference/factories/factory_pipeline/#pxtextmining.factories.factory_pipeline.factory_pipeline","text":"Prepare and fit a text classification pipeline. The pipeline is then fitted using Randomized Search to identify the best performing model and hyperparameters. Feature engineering: Converts text into TF-IDFs or GloVe word vectors with spaCy ; Applies sklearn.preprocessing.KBinsDiscretizer to the text length and sentiment indicator features, and sklearn.preprocessing.StandardScaler to the embeddings (word vectors); Up-sampling of rare classes: uses imblearn.over_sampling.RandomOverSampler to up-sample rare classes Tokenization and lemmatization of the text feature: uses spaCy (default) or NLTK Feature selection: Uses sklearn.feature_selection.SelectPercentile with sklearn.feature_selection.chi2 for TF-IDFs or sklearn.feature_selection.f_classif for embeddings. Fitting and benchmarking of user-supplied Scikit-learn classifiers A param_grid containing a range of hyperparameters to test is created depending on the tokenizer and the learners chosen. The values in the grid are currently lists/tuples of values that are defined either empirically or are based on the published literature (e.g. for Random Forest, see Probst et al. 2019 . Values may be replaced by appropriate distributions in a future release. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default ordinal bool Whether to fit an ordinal classification model. The ordinal model is the implementation of Frank and Hall (2001) that can use any standard classification model that calculates probabilities. False x pd.DataFrame The text feature. required y pd.Series The response variable (target). required tknz str Tokenizer to use (\"spacy\" or \"wordnet\"). 'spacy' metric str Scorer to use during pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' cv int Number of cross-validation folds. 5 n_iter int Number of parameter settings that are sampled in the RandomizedSearch. 100 n_jobs int Number of jobs to run in parallel in the RandomizedSearch. 5 verbose int Controls the verbosity in the RandomizedSearch. 1 learners list A list of Scikit-learn names of the learners to tune. Must be one or more of \"SGDClassifier\", \"RidgeClassifier\", \"Perceptron\", \"PassiveAggressiveClassifier\", \"BernoulliNB\", \"ComplementNB\", \"MultinomialNB\", \"KNeighborsClassifier\", \"NearestCentroid\", \"RandomForestClassifier\". When a single model is used, it can be passed as a string. ['SGDClassifier', 'RidgeClassifier', 'Perceptron', 'PassiveAggressiveClassifier', 'BernoulliNB', 'ComplementNB', 'MultinomialNB', 'RandomForestClassifier'] theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description sklearn.pipeline.Pipeline A tuned sklearn.pipeline.Pipeline","title":"factory_pipeline()"},{"location":"reference/factories/factory_predict_unlabelled_text/","text":"factory_predict_unlabelled_text factory_predict_unlabelled_text(dataset, predictor, pipe_path_or_object, columns_to_return='all_cols', theme=None) Predict unlabelled text data using a fitted model or pipeline. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default dataset pd.DataFrame A pandas.DataFrame (or an objsect that can be converted into such) with the text data to predict classes for. required predictor str The column name in the dataset containing the text to be processed and used for generating predictions. required pipe_path_or_object estimator A fitted model or pipeline. required columns_to_return str_or_list Determines which columns to return once predictions are made. Str options are 'all_cols' which returns all columns (default) or 'preds_only' which returns only the predictions. If a specific selection of columns is required please provide the column names as strings inside a list, e.g. ['feedback', 'organization']. The 'predictions' column will always be included in the returned dataframe. 'all_cols' theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description pd.DataFrame A pandas.DataFrame with the predictions in a column named 'predictions' and any other columns supplied in columns_to_return .","title":"Factory predict unlabelled text"},{"location":"reference/factories/factory_predict_unlabelled_text/#pxtextmining.factories.factory_predict_unlabelled_text","text":"","title":"factory_predict_unlabelled_text"},{"location":"reference/factories/factory_predict_unlabelled_text/#pxtextmining.factories.factory_predict_unlabelled_text.factory_predict_unlabelled_text","text":"Predict unlabelled text data using a fitted model or pipeline. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default dataset pd.DataFrame A pandas.DataFrame (or an objsect that can be converted into such) with the text data to predict classes for. required predictor str The column name in the dataset containing the text to be processed and used for generating predictions. required pipe_path_or_object estimator A fitted model or pipeline. required columns_to_return str_or_list Determines which columns to return once predictions are made. Str options are 'all_cols' which returns all columns (default) or 'preds_only' which returns only the predictions. If a specific selection of columns is required please provide the column names as strings inside a list, e.g. ['feedback', 'organization']. The 'predictions' column will always be included in the returned dataframe. 'all_cols' theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description pd.DataFrame A pandas.DataFrame with the predictions in a column named 'predictions' and any other columns supplied in columns_to_return .","title":"factory_predict_unlabelled_text()"},{"location":"reference/factories/factory_write_results/","text":"factory_write_results write_model_summary(results_file, model_summary) Function to write a .txt file containing the model summary information. Args: results_file (str): Filepath for the output of the pipeline to be saved. model_summary (dict): Model metadata to be written. factory_write_results(pipe, tuning_results, pred, accuracy_per_class, p_compare_models_bar, target, index_training_data, index_test_data, metric, model_summary, objects_to_save=['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'], save_objects_to_server=False, save_objects_to_disk=True, save_pipeline_as='default', results_folder_name='results') Write the fitted pipeline and associated files. Writes between 1 to 7 files, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG); The model summary (txt) Parameters: Name Type Description Default pipe estimator Fitted model or pipeline required tuning_results pandas.core.frame.DataFrame All (hyper)parameter values and models tried during fitting. required pred pandas.core.frame.DataFrame The predictions on the test set. required accuracy_per_class pandas.core.frame.DataFrame Accuracies per class. required p_compare_models_bar png A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best hyperparameter values for each learner. required target str Name of the response variable. required x_train pandas.core.frame.DataFrame The training dataset. required x_test pandas.core.frame.DataFrame The test dataset. required metric str Scorer that was used in pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\" or \"class_balance_accuracy_score\"). required objects_to_save list[str] The objects to save. Should be one or more of \"pipeline\", \"tuning results\", \"predictions\", \"accuracy per class\", \"index - training data\", \"index - test data\", \"bar plot\". ['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'] save_objects_to_server bool Whether to save the results to the server. NOTE: The feature that writes results to the database is for internal use only. Experienced users who would like to write the data to their own databases can, of course, achieve that by slightly modifying the relevant lines in the script. False save_objects_to_disk bool Whether to save the results to disk. See results_folder_name . True save_pipeline_as str Name of saved pipeline. If \"default\", then it will be saved as 'pipeline_' + target + '.sav' . 'default' results_folder_name str Name of the folder that will contain all saved results specified in objects_to_save . If the folder already exists, it will be overwritten. 'results' Returns: Type Description tuple A tuple of length 1 to 7, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG)","title":"Factory write results"},{"location":"reference/factories/factory_write_results/#pxtextmining.factories.factory_write_results","text":"","title":"factory_write_results"},{"location":"reference/factories/factory_write_results/#pxtextmining.factories.factory_write_results.write_model_summary","text":"Function to write a .txt file containing the model summary information. Args: results_file (str): Filepath for the output of the pipeline to be saved. model_summary (dict): Model metadata to be written.","title":"write_model_summary()"},{"location":"reference/factories/factory_write_results/#pxtextmining.factories.factory_write_results.factory_write_results","text":"Write the fitted pipeline and associated files. Writes between 1 to 7 files, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG); The model summary (txt) Parameters: Name Type Description Default pipe estimator Fitted model or pipeline required tuning_results pandas.core.frame.DataFrame All (hyper)parameter values and models tried during fitting. required pred pandas.core.frame.DataFrame The predictions on the test set. required accuracy_per_class pandas.core.frame.DataFrame Accuracies per class. required p_compare_models_bar png A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best hyperparameter values for each learner. required target str Name of the response variable. required x_train pandas.core.frame.DataFrame The training dataset. required x_test pandas.core.frame.DataFrame The test dataset. required metric str Scorer that was used in pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\" or \"class_balance_accuracy_score\"). required objects_to_save list[str] The objects to save. Should be one or more of \"pipeline\", \"tuning results\", \"predictions\", \"accuracy per class\", \"index - training data\", \"index - test data\", \"bar plot\". ['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'] save_objects_to_server bool Whether to save the results to the server. NOTE: The feature that writes results to the database is for internal use only. Experienced users who would like to write the data to their own databases can, of course, achieve that by slightly modifying the relevant lines in the script. False save_objects_to_disk bool Whether to save the results to disk. See results_folder_name . True save_pipeline_as str Name of saved pipeline. If \"default\", then it will be saved as 'pipeline_' + target + '.sav' . 'default' results_folder_name str Name of the folder that will contain all saved results specified in objects_to_save . If the folder already exists, it will be overwritten. 'results' Returns: Type Description tuple A tuple of length 1 to 7, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG)","title":"factory_write_results()"},{"location":"reference/helpers/decode_emojis/","text":"decode_emojis decode_emojis(text_string) Converts emojis into \" text \" (where \"text\" is the emoji name) Parameters: Name Type Description Default text_string str Text string required Returns: Type Description str text_string : Text string with decoded emojis Source code in pxtextmining/helpers/decode_emojis.py def decode_emojis(text_string): \"\"\" Converts emojis into \" __text__ \" (where \"text\" is the emoji name) :param str text_string: Text string :return: text_string : Text string with decoded emojis :rtype: str \"\"\" text_string = str(text_string) text_string = emojis.decode(text_string) pattern = \"\\:(.*?)\\:\" # Decoded emojis are enclosed inside \":\", e.g. \":blush:\" pattern_search = re.search(pattern, text_string) # We want to tell the model that words inside \":\" are decoded emojis. # However, \"[^\\w]\" removes \":\". It doesn't remove \"_\" or \"__\" though, so we may enclose decoded emojis # inside \"__\" instead. if pattern_search is not None: emoji_decoded = pattern_search.group(1) text_string = re.sub(pattern, \" __\" + emoji_decoded + \"__ \", text_string) return text_string","title":"Decode emojis"},{"location":"reference/helpers/decode_emojis/#pxtextmining.helpers.decode_emojis","text":"","title":"decode_emojis"},{"location":"reference/helpers/decode_emojis/#pxtextmining.helpers.decode_emojis.decode_emojis","text":"Converts emojis into \" text \" (where \"text\" is the emoji name) Parameters: Name Type Description Default text_string str Text string required Returns: Type Description str text_string : Text string with decoded emojis Source code in pxtextmining/helpers/decode_emojis.py def decode_emojis(text_string): \"\"\" Converts emojis into \" __text__ \" (where \"text\" is the emoji name) :param str text_string: Text string :return: text_string : Text string with decoded emojis :rtype: str \"\"\" text_string = str(text_string) text_string = emojis.decode(text_string) pattern = \"\\:(.*?)\\:\" # Decoded emojis are enclosed inside \":\", e.g. \":blush:\" pattern_search = re.search(pattern, text_string) # We want to tell the model that words inside \":\" are decoded emojis. # However, \"[^\\w]\" removes \":\". It doesn't remove \"_\" or \"__\" though, so we may enclose decoded emojis # inside \"__\" instead. if pattern_search is not None: emoji_decoded = pattern_search.group(1) text_string = re.sub(pattern, \" __\" + emoji_decoded + \"__ \", text_string) return text_string","title":"decode_emojis()"},{"location":"reference/helpers/estimator_switcher/","text":"estimator_switcher ClfSwitcher Bases: BaseEstimator Class to add different learners as pipeline parameters in a sklearn.pipeline.Pipeline or imblearn.pipeline.Pipeline . Code taken from this post Source code in pxtextmining/helpers/estimator_switcher.py class ClfSwitcher(BaseEstimator): \"\"\" Class to add different learners as pipeline parameters in a [sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) or [imblearn.pipeline.Pipeline](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline). Code taken from [this post](https://stackoverflow.com/questions/48507651/multiple-classification-models-in-a-scikit-pipeline-python) \"\"\" def __init__(self, estimator=SGDClassifier(max_iter=10000)): self.estimator = estimator def fit(self, X, y=None, **kwargs): self.estimator.fit(X, y) return self def predict(self, X, y=None): return self.estimator.predict(X) def predict_proba(self, X): return self.estimator.predict_proba(X) def score(self, X, y): return self.estimator.score(X, y) estimator = estimator instance-attribute __init__(estimator=SGDClassifier(max_iter=10000)) Source code in pxtextmining/helpers/estimator_switcher.py def __init__(self, estimator=SGDClassifier(max_iter=10000)): self.estimator = estimator fit(X, y=None, **kwargs) Source code in pxtextmining/helpers/estimator_switcher.py def fit(self, X, y=None, **kwargs): self.estimator.fit(X, y) return self predict(X, y=None) Source code in pxtextmining/helpers/estimator_switcher.py def predict(self, X, y=None): return self.estimator.predict(X) predict_proba(X) Source code in pxtextmining/helpers/estimator_switcher.py def predict_proba(self, X): return self.estimator.predict_proba(X) score(X, y) Source code in pxtextmining/helpers/estimator_switcher.py def score(self, X, y): return self.estimator.score(X, y)","title":"Estimator switcher"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher","text":"","title":"estimator_switcher"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher","text":"Bases: BaseEstimator Class to add different learners as pipeline parameters in a sklearn.pipeline.Pipeline or imblearn.pipeline.Pipeline . Code taken from this post Source code in pxtextmining/helpers/estimator_switcher.py class ClfSwitcher(BaseEstimator): \"\"\" Class to add different learners as pipeline parameters in a [sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) or [imblearn.pipeline.Pipeline](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html#imblearn.pipeline.Pipeline). Code taken from [this post](https://stackoverflow.com/questions/48507651/multiple-classification-models-in-a-scikit-pipeline-python) \"\"\" def __init__(self, estimator=SGDClassifier(max_iter=10000)): self.estimator = estimator def fit(self, X, y=None, **kwargs): self.estimator.fit(X, y) return self def predict(self, X, y=None): return self.estimator.predict(X) def predict_proba(self, X): return self.estimator.predict_proba(X) def score(self, X, y): return self.estimator.score(X, y)","title":"ClfSwitcher"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.estimator","text":"","title":"estimator"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.__init__","text":"Source code in pxtextmining/helpers/estimator_switcher.py def __init__(self, estimator=SGDClassifier(max_iter=10000)): self.estimator = estimator","title":"__init__()"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.fit","text":"Source code in pxtextmining/helpers/estimator_switcher.py def fit(self, X, y=None, **kwargs): self.estimator.fit(X, y) return self","title":"fit()"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.predict","text":"Source code in pxtextmining/helpers/estimator_switcher.py def predict(self, X, y=None): return self.estimator.predict(X)","title":"predict()"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.predict_proba","text":"Source code in pxtextmining/helpers/estimator_switcher.py def predict_proba(self, X): return self.estimator.predict_proba(X)","title":"predict_proba()"},{"location":"reference/helpers/estimator_switcher/#pxtextmining.helpers.estimator_switcher.ClfSwitcher.score","text":"Source code in pxtextmining/helpers/estimator_switcher.py def score(self, X, y): return self.estimator.score(X, y)","title":"score()"},{"location":"reference/helpers/feature_selection_switcher/","text":"feature_selection_switcher FeatureSelectionSwitcher Bases: BaseEstimator , TransformerMixin Class for choosing between Scikit-learn feature selection tests for use with sklearn.feature_selection.SelectPercentile . Source code in pxtextmining/helpers/feature_selection_switcher.py class FeatureSelectionSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for choosing between Scikit-learn [feature selection tests](https://scikit-learn.org/stable/modules/feature_selection.html#) for use with [sklearn.feature_selection.SelectPercentile](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html). \"\"\" def __init__(self, selector=SelectPercentile()): self.selector = selector def fit(self, X, y, **kwargs): self.selector.fit(X, y) return self def transform(self, X, y=None, **kwargs): return self.selector.transform(X) selector = selector instance-attribute __init__(selector=SelectPercentile()) Source code in pxtextmining/helpers/feature_selection_switcher.py def __init__(self, selector=SelectPercentile()): self.selector = selector fit(X, y, **kwargs) Source code in pxtextmining/helpers/feature_selection_switcher.py def fit(self, X, y, **kwargs): self.selector.fit(X, y) return self transform(X, y=None, **kwargs) Source code in pxtextmining/helpers/feature_selection_switcher.py def transform(self, X, y=None, **kwargs): return self.selector.transform(X)","title":"Feature selection switcher"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher","text":"","title":"feature_selection_switcher"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher.FeatureSelectionSwitcher","text":"Bases: BaseEstimator , TransformerMixin Class for choosing between Scikit-learn feature selection tests for use with sklearn.feature_selection.SelectPercentile . Source code in pxtextmining/helpers/feature_selection_switcher.py class FeatureSelectionSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for choosing between Scikit-learn [feature selection tests](https://scikit-learn.org/stable/modules/feature_selection.html#) for use with [sklearn.feature_selection.SelectPercentile](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html). \"\"\" def __init__(self, selector=SelectPercentile()): self.selector = selector def fit(self, X, y, **kwargs): self.selector.fit(X, y) return self def transform(self, X, y=None, **kwargs): return self.selector.transform(X)","title":"FeatureSelectionSwitcher"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher.FeatureSelectionSwitcher.selector","text":"","title":"selector"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher.FeatureSelectionSwitcher.__init__","text":"Source code in pxtextmining/helpers/feature_selection_switcher.py def __init__(self, selector=SelectPercentile()): self.selector = selector","title":"__init__()"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher.FeatureSelectionSwitcher.fit","text":"Source code in pxtextmining/helpers/feature_selection_switcher.py def fit(self, X, y, **kwargs): self.selector.fit(X, y) return self","title":"fit()"},{"location":"reference/helpers/feature_selection_switcher/#pxtextmining.helpers.feature_selection_switcher.FeatureSelectionSwitcher.transform","text":"Source code in pxtextmining/helpers/feature_selection_switcher.py def transform(self, X, y=None, **kwargs): return self.selector.transform(X)","title":"transform()"},{"location":"reference/helpers/metrics/","text":"metrics class_balance_accuracy_score(y_true, y_pred) Function for Class Balance Accuracy scorer (p. 40 in Mosley 2013 ). Parameters: Name Type Description Default y_true array True classes, shape = [n_samples]. required y_pred array Predicted classes, shape = [n_samples]. required Returns: Type Description float The Class Balance Accuracy score. Source code in pxtextmining/helpers/metrics.py def class_balance_accuracy_score(y_true, y_pred): \"\"\" Function for Class Balance Accuracy scorer (p. 40 in [Mosley 2013](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=4544&context=etd)). :param array y_true: True classes, shape = [n_samples]. :param array y_pred: Predicted classes, shape = [n_samples]. :return: The Class Balance Accuracy score. :rtype: float \"\"\" cm = confusion_matrix(y_true, y_pred) c_i_dot = np.sum(cm, axis=1) c_dot_i = np.sum(cm, axis=0) cba = [] for i in range(len(c_dot_i)): cba.append(cm[i][i] / max(c_i_dot[i], c_dot_i[i])) cba = sum(cba) / (i + 1) return cba","title":"Metrics"},{"location":"reference/helpers/metrics/#pxtextmining.helpers.metrics","text":"","title":"metrics"},{"location":"reference/helpers/metrics/#pxtextmining.helpers.metrics.class_balance_accuracy_score","text":"Function for Class Balance Accuracy scorer (p. 40 in Mosley 2013 ). Parameters: Name Type Description Default y_true array True classes, shape = [n_samples]. required y_pred array Predicted classes, shape = [n_samples]. required Returns: Type Description float The Class Balance Accuracy score. Source code in pxtextmining/helpers/metrics.py def class_balance_accuracy_score(y_true, y_pred): \"\"\" Function for Class Balance Accuracy scorer (p. 40 in [Mosley 2013](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=4544&context=etd)). :param array y_true: True classes, shape = [n_samples]. :param array y_pred: Predicted classes, shape = [n_samples]. :return: The Class Balance Accuracy score. :rtype: float \"\"\" cm = confusion_matrix(y_true, y_pred) c_i_dot = np.sum(cm, axis=1) c_dot_i = np.sum(cm, axis=0) cba = [] for i in range(len(c_dot_i)): cba.append(cm[i][i] / max(c_i_dot[i], c_dot_i[i])) cba = sum(cba) / (i + 1) return cba","title":"class_balance_accuracy_score()"},{"location":"reference/helpers/ordinal_classification/","text":"ordinal_classification OrdinalClassifier Bases: BaseEstimator Estimator class for building an ordinal classification model using the method of Frank and Hall (2001) based on code published online in this post . NOTE: As described later, the argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels, and is only relevant for models predicting 'criticality'. It can otherwise be safely ignored. Parameters: Name Type Description Default estimator estimator A Scikit-learn classifier. LogisticRegression() clfs dict Helper variable. Defined inside the class. {} y_factorized pd.Series Helper variable. Defined inside the class. None unique_class int Helper variable. Defined inside the class. None class_dict dict Helper variable. Defined inside the class. None theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None target_class_value str The criticality value to assign to \"Couldn't be improved\". '3' theme_class_value int The value of \"Couldn't be improved\" in the transformed (e.g. one-hot encoded) theme column. 1 Source code in pxtextmining/helpers/ordinal_classification.py class OrdinalClassifier(BaseEstimator): \"\"\" Estimator class for building an ordinal classification model using the method of [Frank and Hall (2001)](https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf) based on code published online in [this post](https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c). **NOTE:** As described later, the argument `theme` is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels, and is only relevant for models predicting 'criticality'. It can otherwise be safely ignored. :param estimator estimator: A Scikit-learn classifier. :param dict clfs: Helper variable. Defined inside the class. :param pd.Series y_factorized: Helper variable. Defined inside the class. :param int unique_class: Helper variable. Defined inside the class. :param dict class_dict: Helper variable. Defined inside the class. :param str theme: For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to `None`. If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. :param str target_class_value: The criticality value to assign to \"Couldn't be improved\". :param int theme_class_value: The value of \"Couldn't be improved\" in the transformed (e.g. one-hot encoded) theme column. \"\"\" def __init__(self, estimator=LogisticRegression(), clfs={}, y_factorized=None, unique_class=None, class_dict=None, theme=None, target_class_value='3', theme_class_value=1): self.estimator = estimator self.clfs = clfs self.y_factorized = y_factorized self.unique_class = unique_class self.class_dict = class_dict self.theme = theme self.target_class_value = target_class_value self.theme_class_value = theme_class_value def fit(self, X, y=None, **kwargs): self.y_factorized = pd.Series(y.astype('int64')).factorize(sort=True)[0] self.unique_class = np.sort(np.unique(self.y_factorized)) self.class_dict = dict(zip(self.y_factorized, y)) if self.unique_class.shape[0] > 2: for i in range(self.unique_class.shape[0] - 1): # for each k - 1 ordinal value we fit a binary classification problem y_binary = (self.y_factorized > self.unique_class[i]).astype(np.uint8) estimator = clone(self.estimator) estimator.fit(X, y_binary) self.clfs[i] = estimator return self def predict_proba_all(self, X): clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs} predicted = [] if self.unique_class.shape[0] > 2: for i in self.unique_class: if i == 0: # V1 = 1 - Pr(y > V1) predicted.append(1 - clfs_predict[i][:, 1]) elif i in clfs_predict: # Vi = Pr(y > Vi-1) - Pr(y > Vi) predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1]) else: # Vk = Pr(y > Vk-1) predicted.append(clfs_predict[i - 1][:, 1]) return np.vstack(predicted).T def predict_proba(self, X): return np.max(self.predict_proba_all(X), axis=1) def predict(self, X): y_pred = np.argmax(self.predict_proba_all(X), axis=1) y_pred_orig_class_names = [] for i in y_pred: y_pred_orig_class_names.append(self.class_dict[i]) re = np.array(y_pred_orig_class_names) # This is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme # labels (\"Access\", \"Environment/ facilities\" etc.). We want the criticality for \"Couldn't be improved\" to # always be \"3\" (or theme_class_value). The theme label is passed as a one-hot encoded set of columns, of # which the first is for \"Couldn't be improved\". The one-hot encoded columns are actually the first columns of # the whole sparse matrix that has the TF-IDFs, sentiment features etc. So we want to find the records # with \"Couldn't be improved\" (i.e. records with a value of 1) in the first, one-hot encoded, column and replace # the predicted criticality values with \"3\". if self.theme is not None: if isinstance(X[:, 0], np.ndarray): theme_col = pd.DataFrame(X[:, 0]) else: theme_col = pd.DataFrame(X[:, 0].todense()) no_improvements_index = theme_col.loc[theme_col.iloc[:, 0] == self.theme_class_value].index re = pd.DataFrame(re, columns=['aux'], index=theme_col.index) re.loc[no_improvements_index] = self.target_class_value re = np.array(re.aux) return re def score(self, X, y): return self.estimator.score(X, y) estimator = estimator instance-attribute clfs = clfs instance-attribute y_factorized = y_factorized instance-attribute unique_class = unique_class instance-attribute class_dict = class_dict instance-attribute theme = theme instance-attribute target_class_value = target_class_value instance-attribute theme_class_value = theme_class_value instance-attribute __init__(estimator=LogisticRegression(), clfs={}, y_factorized=None, unique_class=None, class_dict=None, theme=None, target_class_value='3', theme_class_value=1) Source code in pxtextmining/helpers/ordinal_classification.py def __init__(self, estimator=LogisticRegression(), clfs={}, y_factorized=None, unique_class=None, class_dict=None, theme=None, target_class_value='3', theme_class_value=1): self.estimator = estimator self.clfs = clfs self.y_factorized = y_factorized self.unique_class = unique_class self.class_dict = class_dict self.theme = theme self.target_class_value = target_class_value self.theme_class_value = theme_class_value fit(X, y=None, **kwargs) Source code in pxtextmining/helpers/ordinal_classification.py def fit(self, X, y=None, **kwargs): self.y_factorized = pd.Series(y.astype('int64')).factorize(sort=True)[0] self.unique_class = np.sort(np.unique(self.y_factorized)) self.class_dict = dict(zip(self.y_factorized, y)) if self.unique_class.shape[0] > 2: for i in range(self.unique_class.shape[0] - 1): # for each k - 1 ordinal value we fit a binary classification problem y_binary = (self.y_factorized > self.unique_class[i]).astype(np.uint8) estimator = clone(self.estimator) estimator.fit(X, y_binary) self.clfs[i] = estimator return self predict_proba_all(X) Source code in pxtextmining/helpers/ordinal_classification.py def predict_proba_all(self, X): clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs} predicted = [] if self.unique_class.shape[0] > 2: for i in self.unique_class: if i == 0: # V1 = 1 - Pr(y > V1) predicted.append(1 - clfs_predict[i][:, 1]) elif i in clfs_predict: # Vi = Pr(y > Vi-1) - Pr(y > Vi) predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1]) else: # Vk = Pr(y > Vk-1) predicted.append(clfs_predict[i - 1][:, 1]) return np.vstack(predicted).T predict_proba(X) Source code in pxtextmining/helpers/ordinal_classification.py def predict_proba(self, X): return np.max(self.predict_proba_all(X), axis=1) predict(X) Source code in pxtextmining/helpers/ordinal_classification.py def predict(self, X): y_pred = np.argmax(self.predict_proba_all(X), axis=1) y_pred_orig_class_names = [] for i in y_pred: y_pred_orig_class_names.append(self.class_dict[i]) re = np.array(y_pred_orig_class_names) # This is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme # labels (\"Access\", \"Environment/ facilities\" etc.). We want the criticality for \"Couldn't be improved\" to # always be \"3\" (or theme_class_value). The theme label is passed as a one-hot encoded set of columns, of # which the first is for \"Couldn't be improved\". The one-hot encoded columns are actually the first columns of # the whole sparse matrix that has the TF-IDFs, sentiment features etc. So we want to find the records # with \"Couldn't be improved\" (i.e. records with a value of 1) in the first, one-hot encoded, column and replace # the predicted criticality values with \"3\". if self.theme is not None: if isinstance(X[:, 0], np.ndarray): theme_col = pd.DataFrame(X[:, 0]) else: theme_col = pd.DataFrame(X[:, 0].todense()) no_improvements_index = theme_col.loc[theme_col.iloc[:, 0] == self.theme_class_value].index re = pd.DataFrame(re, columns=['aux'], index=theme_col.index) re.loc[no_improvements_index] = self.target_class_value re = np.array(re.aux) return re score(X, y) Source code in pxtextmining/helpers/ordinal_classification.py def score(self, X, y): return self.estimator.score(X, y)","title":"Ordinal classification"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification","text":"","title":"ordinal_classification"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier","text":"Bases: BaseEstimator Estimator class for building an ordinal classification model using the method of Frank and Hall (2001) based on code published online in this post . NOTE: As described later, the argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels, and is only relevant for models predicting 'criticality'. It can otherwise be safely ignored. Parameters: Name Type Description Default estimator estimator A Scikit-learn classifier. LogisticRegression() clfs dict Helper variable. Defined inside the class. {} y_factorized pd.Series Helper variable. Defined inside the class. None unique_class int Helper variable. Defined inside the class. None class_dict dict Helper variable. Defined inside the class. None theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None target_class_value str The criticality value to assign to \"Couldn't be improved\". '3' theme_class_value int The value of \"Couldn't be improved\" in the transformed (e.g. one-hot encoded) theme column. 1 Source code in pxtextmining/helpers/ordinal_classification.py class OrdinalClassifier(BaseEstimator): \"\"\" Estimator class for building an ordinal classification model using the method of [Frank and Hall (2001)](https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf) based on code published online in [this post](https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c). **NOTE:** As described later, the argument `theme` is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels, and is only relevant for models predicting 'criticality'. It can otherwise be safely ignored. :param estimator estimator: A Scikit-learn classifier. :param dict clfs: Helper variable. Defined inside the class. :param pd.Series y_factorized: Helper variable. Defined inside the class. :param int unique_class: Helper variable. Defined inside the class. :param dict class_dict: Helper variable. Defined inside the class. :param str theme: For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to `None`. If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. :param str target_class_value: The criticality value to assign to \"Couldn't be improved\". :param int theme_class_value: The value of \"Couldn't be improved\" in the transformed (e.g. one-hot encoded) theme column. \"\"\" def __init__(self, estimator=LogisticRegression(), clfs={}, y_factorized=None, unique_class=None, class_dict=None, theme=None, target_class_value='3', theme_class_value=1): self.estimator = estimator self.clfs = clfs self.y_factorized = y_factorized self.unique_class = unique_class self.class_dict = class_dict self.theme = theme self.target_class_value = target_class_value self.theme_class_value = theme_class_value def fit(self, X, y=None, **kwargs): self.y_factorized = pd.Series(y.astype('int64')).factorize(sort=True)[0] self.unique_class = np.sort(np.unique(self.y_factorized)) self.class_dict = dict(zip(self.y_factorized, y)) if self.unique_class.shape[0] > 2: for i in range(self.unique_class.shape[0] - 1): # for each k - 1 ordinal value we fit a binary classification problem y_binary = (self.y_factorized > self.unique_class[i]).astype(np.uint8) estimator = clone(self.estimator) estimator.fit(X, y_binary) self.clfs[i] = estimator return self def predict_proba_all(self, X): clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs} predicted = [] if self.unique_class.shape[0] > 2: for i in self.unique_class: if i == 0: # V1 = 1 - Pr(y > V1) predicted.append(1 - clfs_predict[i][:, 1]) elif i in clfs_predict: # Vi = Pr(y > Vi-1) - Pr(y > Vi) predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1]) else: # Vk = Pr(y > Vk-1) predicted.append(clfs_predict[i - 1][:, 1]) return np.vstack(predicted).T def predict_proba(self, X): return np.max(self.predict_proba_all(X), axis=1) def predict(self, X): y_pred = np.argmax(self.predict_proba_all(X), axis=1) y_pred_orig_class_names = [] for i in y_pred: y_pred_orig_class_names.append(self.class_dict[i]) re = np.array(y_pred_orig_class_names) # This is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme # labels (\"Access\", \"Environment/ facilities\" etc.). We want the criticality for \"Couldn't be improved\" to # always be \"3\" (or theme_class_value). The theme label is passed as a one-hot encoded set of columns, of # which the first is for \"Couldn't be improved\". The one-hot encoded columns are actually the first columns of # the whole sparse matrix that has the TF-IDFs, sentiment features etc. So we want to find the records # with \"Couldn't be improved\" (i.e. records with a value of 1) in the first, one-hot encoded, column and replace # the predicted criticality values with \"3\". if self.theme is not None: if isinstance(X[:, 0], np.ndarray): theme_col = pd.DataFrame(X[:, 0]) else: theme_col = pd.DataFrame(X[:, 0].todense()) no_improvements_index = theme_col.loc[theme_col.iloc[:, 0] == self.theme_class_value].index re = pd.DataFrame(re, columns=['aux'], index=theme_col.index) re.loc[no_improvements_index] = self.target_class_value re = np.array(re.aux) return re def score(self, X, y): return self.estimator.score(X, y)","title":"OrdinalClassifier"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.estimator","text":"","title":"estimator"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.clfs","text":"","title":"clfs"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.y_factorized","text":"","title":"y_factorized"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.unique_class","text":"","title":"unique_class"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.class_dict","text":"","title":"class_dict"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.theme","text":"","title":"theme"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.target_class_value","text":"","title":"target_class_value"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.theme_class_value","text":"","title":"theme_class_value"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.__init__","text":"Source code in pxtextmining/helpers/ordinal_classification.py def __init__(self, estimator=LogisticRegression(), clfs={}, y_factorized=None, unique_class=None, class_dict=None, theme=None, target_class_value='3', theme_class_value=1): self.estimator = estimator self.clfs = clfs self.y_factorized = y_factorized self.unique_class = unique_class self.class_dict = class_dict self.theme = theme self.target_class_value = target_class_value self.theme_class_value = theme_class_value","title":"__init__()"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.fit","text":"Source code in pxtextmining/helpers/ordinal_classification.py def fit(self, X, y=None, **kwargs): self.y_factorized = pd.Series(y.astype('int64')).factorize(sort=True)[0] self.unique_class = np.sort(np.unique(self.y_factorized)) self.class_dict = dict(zip(self.y_factorized, y)) if self.unique_class.shape[0] > 2: for i in range(self.unique_class.shape[0] - 1): # for each k - 1 ordinal value we fit a binary classification problem y_binary = (self.y_factorized > self.unique_class[i]).astype(np.uint8) estimator = clone(self.estimator) estimator.fit(X, y_binary) self.clfs[i] = estimator return self","title":"fit()"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.predict_proba_all","text":"Source code in pxtextmining/helpers/ordinal_classification.py def predict_proba_all(self, X): clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs} predicted = [] if self.unique_class.shape[0] > 2: for i in self.unique_class: if i == 0: # V1 = 1 - Pr(y > V1) predicted.append(1 - clfs_predict[i][:, 1]) elif i in clfs_predict: # Vi = Pr(y > Vi-1) - Pr(y > Vi) predicted.append(clfs_predict[i - 1][:, 1] - clfs_predict[i][:, 1]) else: # Vk = Pr(y > Vk-1) predicted.append(clfs_predict[i - 1][:, 1]) return np.vstack(predicted).T","title":"predict_proba_all()"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.predict_proba","text":"Source code in pxtextmining/helpers/ordinal_classification.py def predict_proba(self, X): return np.max(self.predict_proba_all(X), axis=1)","title":"predict_proba()"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.predict","text":"Source code in pxtextmining/helpers/ordinal_classification.py def predict(self, X): y_pred = np.argmax(self.predict_proba_all(X), axis=1) y_pred_orig_class_names = [] for i in y_pred: y_pred_orig_class_names.append(self.class_dict[i]) re = np.array(y_pred_orig_class_names) # This is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme # labels (\"Access\", \"Environment/ facilities\" etc.). We want the criticality for \"Couldn't be improved\" to # always be \"3\" (or theme_class_value). The theme label is passed as a one-hot encoded set of columns, of # which the first is for \"Couldn't be improved\". The one-hot encoded columns are actually the first columns of # the whole sparse matrix that has the TF-IDFs, sentiment features etc. So we want to find the records # with \"Couldn't be improved\" (i.e. records with a value of 1) in the first, one-hot encoded, column and replace # the predicted criticality values with \"3\". if self.theme is not None: if isinstance(X[:, 0], np.ndarray): theme_col = pd.DataFrame(X[:, 0]) else: theme_col = pd.DataFrame(X[:, 0].todense()) no_improvements_index = theme_col.loc[theme_col.iloc[:, 0] == self.theme_class_value].index re = pd.DataFrame(re, columns=['aux'], index=theme_col.index) re.loc[no_improvements_index] = self.target_class_value re = np.array(re.aux) return re","title":"predict()"},{"location":"reference/helpers/ordinal_classification/#pxtextmining.helpers.ordinal_classification.OrdinalClassifier.score","text":"Source code in pxtextmining/helpers/ordinal_classification.py def score(self, X, y): return self.estimator.score(X, y)","title":"score()"},{"location":"reference/helpers/oversampling/","text":"oversampling random_over_sampler_dictionary(y, threshold=200, up_balancing_counts=300) Function that detects rare classes. Finds classes with counts fewer than a specified threshold. The function performs a few validity checks: The threshold must be smaller than the up-balancing number(s). When it is not, the latter takes the value of the former. When the up-balancing number is zero or the threshold is smaller than all class counts, then the function returns the original counts. The validity checks ensure that the function does not stop the script. It is completely the user's responsibility to ensure that the supplied values are meaningful. For example, if each of the rare classes are > 200 in number but the threshold were 100 in one run and 150 in another run of the pipeline, then the result would be the original counts in both cases, i.e. there would be a redundant repetition of runs. Finally, the up-balancing number can be 0, an integer or a list of integers with length = number of rare classes. It is the user's responsibility to ensure that, when it is a list, it has the correct length. Parameters: Name Type Description Default y ndarray The dependent variable. Shape (n_samples, ). required threshold int The class count below which a class is considered rare. 200 up_balancing_counts array[int] The number by which to up-balance a class. 300 Returns: Type Description dict rare_classes: Keys are the rare classes and values are the user-specified up-balancing numbers for each class. Source code in pxtextmining/helpers/oversampling.py def random_over_sampler_dictionary(y, threshold=200, up_balancing_counts=300): \"\"\" Function that detects rare classes. Finds classes with counts fewer than a specified threshold. The function performs a few validity checks: 1. The threshold must be smaller than the up-balancing number(s). When it is not, the latter takes the value of the former. 2. When the up-balancing number is zero or the threshold is smaller than all class counts, then the function returns the original counts. The validity checks ensure that the function does not stop the script. It is completely the user's responsibility to ensure that the supplied values are meaningful. For example, if each of the rare classes are > 200 in number but the threshold were 100 in one run and 150 in another run of the pipeline, then the result would be the original counts in both cases, i.e. there would be a redundant repetition of runs. Finally, the up-balancing number can be 0, an integer or a list of integers with length = number of rare classes. It is the user's responsibility to ensure that, when it is a list, it has the correct length. :param ndarray y: The dependent variable. Shape (n_samples, ). :param int threshold: The class count below which a class is considered rare. :param array[int] up_balancing_counts: The number by which to up-balance a class. :return: rare_classes: Keys are the rare classes and values are the user-specified up-balancing numbers for each class. :rtype: dict \"\"\" unique, frequency = np.unique(y, return_counts=True) rare_classes = pd.DataFrame() rare_classes['counts'], rare_classes.index = frequency, unique if type(up_balancing_counts) is int: up_balancing_counts = [up_balancing_counts] aux = list(filter(lambda x: up_balancing_counts[x] < threshold, range(len(up_balancing_counts)))) if any(x < threshold for x in up_balancing_counts): for i in aux: print(\"The supplied up-balancing value for class \" + rare_classes.index[aux] + \" is smaller than the supplied threshold value. \" \"Setting up_balancing_counts = threshold for this class\") up_balancing_counts[i] = threshold if (len(rare_classes[rare_classes.counts < threshold]) == 0) or (up_balancing_counts == [0]): rare_classes = rare_classes.to_dict()['counts'] else: rare_classes = rare_classes[rare_classes.counts < threshold] if len(up_balancing_counts) != 1: rare_classes.counts = up_balancing_counts else: rare_classes.counts = up_balancing_counts * len(rare_classes.counts) rare_classes = rare_classes.to_dict()['counts'] return rare_classes random_over_sampler_data_generator(X, y, threshold=200, up_balancing_counts=300, random_state=0) Uses random_over_sampler_dictionary() to return the up-balanced dataset. Can be passed to imblearn.FunctionSampler to be then passed to imblearn.pipeline. Parameters: Name Type Description Default X ndarray The features table. Shape (n_samples, n_features) required y ndarray The dependent variable. Shape (n_samples, ). required threshold int The class count below which a class is considered rare. 200 up_balancing_counts array[int] The number by which to up-balance a class. 300 random_state int RandomState instance or None , optional (default= None ). 0 Returns: Type Description pd.DataFrame dataset with up-balanced minority classes Source code in pxtextmining/helpers/oversampling.py def random_over_sampler_data_generator(X, y, threshold=200, up_balancing_counts=300, random_state=0): \"\"\" Uses random_over_sampler_dictionary() to return the up-balanced dataset. Can be passed to imblearn.FunctionSampler to be then passed to imblearn.pipeline. :param ndarray X: The features table. Shape (n_samples, n_features) :param ndarray y: The dependent variable. Shape (n_samples, ). :param int threshold: The class count below which a class is considered rare. :param array[int] up_balancing_counts: The number by which to up-balance a class. :param int random_state: RandomState instance or ``None``, optional (default=``None``). :return: dataset with up-balanced minority classes :rtype: pd.DataFrame \"\"\" aux = random_over_sampler_dictionary(y, threshold, up_balancing_counts) return RandomOverSampler( sampling_strategy=aux, random_state=random_state).fit_resample(X, y)","title":"Oversampling"},{"location":"reference/helpers/oversampling/#pxtextmining.helpers.oversampling","text":"","title":"oversampling"},{"location":"reference/helpers/oversampling/#pxtextmining.helpers.oversampling.random_over_sampler_dictionary","text":"Function that detects rare classes. Finds classes with counts fewer than a specified threshold. The function performs a few validity checks: The threshold must be smaller than the up-balancing number(s). When it is not, the latter takes the value of the former. When the up-balancing number is zero or the threshold is smaller than all class counts, then the function returns the original counts. The validity checks ensure that the function does not stop the script. It is completely the user's responsibility to ensure that the supplied values are meaningful. For example, if each of the rare classes are > 200 in number but the threshold were 100 in one run and 150 in another run of the pipeline, then the result would be the original counts in both cases, i.e. there would be a redundant repetition of runs. Finally, the up-balancing number can be 0, an integer or a list of integers with length = number of rare classes. It is the user's responsibility to ensure that, when it is a list, it has the correct length. Parameters: Name Type Description Default y ndarray The dependent variable. Shape (n_samples, ). required threshold int The class count below which a class is considered rare. 200 up_balancing_counts array[int] The number by which to up-balance a class. 300 Returns: Type Description dict rare_classes: Keys are the rare classes and values are the user-specified up-balancing numbers for each class. Source code in pxtextmining/helpers/oversampling.py def random_over_sampler_dictionary(y, threshold=200, up_balancing_counts=300): \"\"\" Function that detects rare classes. Finds classes with counts fewer than a specified threshold. The function performs a few validity checks: 1. The threshold must be smaller than the up-balancing number(s). When it is not, the latter takes the value of the former. 2. When the up-balancing number is zero or the threshold is smaller than all class counts, then the function returns the original counts. The validity checks ensure that the function does not stop the script. It is completely the user's responsibility to ensure that the supplied values are meaningful. For example, if each of the rare classes are > 200 in number but the threshold were 100 in one run and 150 in another run of the pipeline, then the result would be the original counts in both cases, i.e. there would be a redundant repetition of runs. Finally, the up-balancing number can be 0, an integer or a list of integers with length = number of rare classes. It is the user's responsibility to ensure that, when it is a list, it has the correct length. :param ndarray y: The dependent variable. Shape (n_samples, ). :param int threshold: The class count below which a class is considered rare. :param array[int] up_balancing_counts: The number by which to up-balance a class. :return: rare_classes: Keys are the rare classes and values are the user-specified up-balancing numbers for each class. :rtype: dict \"\"\" unique, frequency = np.unique(y, return_counts=True) rare_classes = pd.DataFrame() rare_classes['counts'], rare_classes.index = frequency, unique if type(up_balancing_counts) is int: up_balancing_counts = [up_balancing_counts] aux = list(filter(lambda x: up_balancing_counts[x] < threshold, range(len(up_balancing_counts)))) if any(x < threshold for x in up_balancing_counts): for i in aux: print(\"The supplied up-balancing value for class \" + rare_classes.index[aux] + \" is smaller than the supplied threshold value. \" \"Setting up_balancing_counts = threshold for this class\") up_balancing_counts[i] = threshold if (len(rare_classes[rare_classes.counts < threshold]) == 0) or (up_balancing_counts == [0]): rare_classes = rare_classes.to_dict()['counts'] else: rare_classes = rare_classes[rare_classes.counts < threshold] if len(up_balancing_counts) != 1: rare_classes.counts = up_balancing_counts else: rare_classes.counts = up_balancing_counts * len(rare_classes.counts) rare_classes = rare_classes.to_dict()['counts'] return rare_classes","title":"random_over_sampler_dictionary()"},{"location":"reference/helpers/oversampling/#pxtextmining.helpers.oversampling.random_over_sampler_data_generator","text":"Uses random_over_sampler_dictionary() to return the up-balanced dataset. Can be passed to imblearn.FunctionSampler to be then passed to imblearn.pipeline. Parameters: Name Type Description Default X ndarray The features table. Shape (n_samples, n_features) required y ndarray The dependent variable. Shape (n_samples, ). required threshold int The class count below which a class is considered rare. 200 up_balancing_counts array[int] The number by which to up-balance a class. 300 random_state int RandomState instance or None , optional (default= None ). 0 Returns: Type Description pd.DataFrame dataset with up-balanced minority classes Source code in pxtextmining/helpers/oversampling.py def random_over_sampler_data_generator(X, y, threshold=200, up_balancing_counts=300, random_state=0): \"\"\" Uses random_over_sampler_dictionary() to return the up-balanced dataset. Can be passed to imblearn.FunctionSampler to be then passed to imblearn.pipeline. :param ndarray X: The features table. Shape (n_samples, n_features) :param ndarray y: The dependent variable. Shape (n_samples, ). :param int threshold: The class count below which a class is considered rare. :param array[int] up_balancing_counts: The number by which to up-balance a class. :param int random_state: RandomState instance or ``None``, optional (default=``None``). :return: dataset with up-balanced minority classes :rtype: pd.DataFrame \"\"\" aux = random_over_sampler_dictionary(y, threshold, up_balancing_counts) return RandomOverSampler( sampling_strategy=aux, random_state=random_state).fit_resample(X, y)","title":"random_over_sampler_data_generator()"},{"location":"reference/helpers/passthrough/","text":"passthrough Passthrough Bases: BaseEstimator , TransformerMixin Class for passing through features that require no preprocessing. Taken from this guide Source code in pxtextmining/helpers/passthrough.py class Passthrough(BaseEstimator, TransformerMixin): \"\"\" Class for passing through features that require no preprocessing. Taken from [this guide](https://stackoverflow.com/questions/54592115/appending-the-columntransformer-result-to-the-original-data-within-a-pipeline) \"\"\" def fit(self, X, y=None): return self def transform(self, X): # Single-column data frames are Pandas series, which Scikit-learn doesn't know how to deal with. Make sure that # result is always a data frame. X = pd.DataFrame(X) return X fit(X, y=None) Source code in pxtextmining/helpers/passthrough.py def fit(self, X, y=None): return self transform(X) Source code in pxtextmining/helpers/passthrough.py def transform(self, X): # Single-column data frames are Pandas series, which Scikit-learn doesn't know how to deal with. Make sure that # result is always a data frame. X = pd.DataFrame(X) return X","title":"Passthrough"},{"location":"reference/helpers/passthrough/#pxtextmining.helpers.passthrough","text":"","title":"passthrough"},{"location":"reference/helpers/passthrough/#pxtextmining.helpers.passthrough.Passthrough","text":"Bases: BaseEstimator , TransformerMixin Class for passing through features that require no preprocessing. Taken from this guide Source code in pxtextmining/helpers/passthrough.py class Passthrough(BaseEstimator, TransformerMixin): \"\"\" Class for passing through features that require no preprocessing. Taken from [this guide](https://stackoverflow.com/questions/54592115/appending-the-columntransformer-result-to-the-original-data-within-a-pipeline) \"\"\" def fit(self, X, y=None): return self def transform(self, X): # Single-column data frames are Pandas series, which Scikit-learn doesn't know how to deal with. Make sure that # result is always a data frame. X = pd.DataFrame(X) return X","title":"Passthrough"},{"location":"reference/helpers/passthrough/#pxtextmining.helpers.passthrough.Passthrough.fit","text":"Source code in pxtextmining/helpers/passthrough.py def fit(self, X, y=None): return self","title":"fit()"},{"location":"reference/helpers/passthrough/#pxtextmining.helpers.passthrough.Passthrough.transform","text":"Source code in pxtextmining/helpers/passthrough.py def transform(self, X): # Single-column data frames are Pandas series, which Scikit-learn doesn't know how to deal with. Make sure that # result is always a data frame. X = pd.DataFrame(X) return X","title":"transform()"},{"location":"reference/helpers/scaler_switcher/","text":"scaler_switcher ScalerSwitcher Bases: BaseEstimator , TransformerMixin Class for switching between Scikit-learn scalers and preprocessors in the randomized search. Source code in pxtextmining/helpers/scaler_switcher.py class ScalerSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for switching between ``Scikit-learn`` [scalers and preprocessors](https://scikit-learn.org/stable/modules/preprocessing.html#) in the randomized search. \"\"\" def __init__(self, scaler=MinMaxScaler()): self.scaler = scaler def fit(self, X, y=None): return self def transform(self, X, y=None): return self.scaler.fit_transform(X) scaler = scaler instance-attribute __init__(scaler=MinMaxScaler()) Source code in pxtextmining/helpers/scaler_switcher.py def __init__(self, scaler=MinMaxScaler()): self.scaler = scaler fit(X, y=None) Source code in pxtextmining/helpers/scaler_switcher.py def fit(self, X, y=None): return self transform(X, y=None) Source code in pxtextmining/helpers/scaler_switcher.py def transform(self, X, y=None): return self.scaler.fit_transform(X)","title":"Scaler switcher"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher","text":"","title":"scaler_switcher"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher.ScalerSwitcher","text":"Bases: BaseEstimator , TransformerMixin Class for switching between Scikit-learn scalers and preprocessors in the randomized search. Source code in pxtextmining/helpers/scaler_switcher.py class ScalerSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for switching between ``Scikit-learn`` [scalers and preprocessors](https://scikit-learn.org/stable/modules/preprocessing.html#) in the randomized search. \"\"\" def __init__(self, scaler=MinMaxScaler()): self.scaler = scaler def fit(self, X, y=None): return self def transform(self, X, y=None): return self.scaler.fit_transform(X)","title":"ScalerSwitcher"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher.ScalerSwitcher.scaler","text":"","title":"scaler"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher.ScalerSwitcher.__init__","text":"Source code in pxtextmining/helpers/scaler_switcher.py def __init__(self, scaler=MinMaxScaler()): self.scaler = scaler","title":"__init__()"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher.ScalerSwitcher.fit","text":"Source code in pxtextmining/helpers/scaler_switcher.py def fit(self, X, y=None): return self","title":"fit()"},{"location":"reference/helpers/scaler_switcher/#pxtextmining.helpers.scaler_switcher.ScalerSwitcher.transform","text":"Source code in pxtextmining/helpers/scaler_switcher.py def transform(self, X, y=None): return self.scaler.fit_transform(X)","title":"transform()"},{"location":"reference/helpers/sentiment_scores/","text":"sentiment_scores sentiment_scores(X) Calculate sentiment indicators from TextBlob <https://textblob.readthedocs.io/en/dev/> (polarity and subjectivity) and vaderSentiment <https://pypi.org/project/vaderSentiment/> (positive, negative and neutral sentiments and compound score). Parameters: Name Type Description Default X pd.DataFrame A dictionary, pandas.DataFrame , tuple or list with the text strings. If it is a dictionary, it must have a single key (column). required Returns: Type Description pd.DataFrame A pandas.DataFrame with the sentiment scores for each text record. Shape [n_samples, 6]. Source code in pxtextmining/helpers/sentiment_scores.py def sentiment_scores(X): \"\"\" Calculate sentiment indicators from `TextBlob <https://textblob.readthedocs.io/en/dev/>`_ (polarity and subjectivity) and `vaderSentiment <https://pypi.org/project/vaderSentiment/>`_ (positive, negative and neutral sentiments and compound score). :param pd.DataFrame X: A dictionary, ``pandas.DataFrame``, tuple or list with the text strings. If it is a dictionary, it must have a single key (column). :return: A ``pandas.DataFrame`` with the sentiment scores for each text record. Shape [n_samples, 6]. :rtype: pd.DataFrame \"\"\" vader_analyser = SentimentIntensityAnalyzer() X = pd.DataFrame(X).copy().rename(lambda x: 'predictor', axis='columns') text_blob_scores = [] vader_scores = [] for i in X.index: text = X.loc[i, 'predictor'] if text is None or str(text) == 'nan': text = '' text_blob_scores.append(TextBlob(text).sentiment) vader_scores.append(vader_analyser.polarity_scores(text)) text_blob_scores_df = pd.DataFrame(text_blob_scores) text_blob_scores_df.columns = 'text_blob_' + text_blob_scores_df.columns text_blob_scores_df.index = X.index vader_scores_df = pd.DataFrame.from_dict(vader_scores) vader_scores_df.columns = 'vader_' + vader_scores_df.columns vader_scores_df.index = X.index all_scores = pd.concat([text_blob_scores_df, vader_scores_df], axis=1, ignore_index=False) return all_scores","title":"Sentiment scores"},{"location":"reference/helpers/sentiment_scores/#pxtextmining.helpers.sentiment_scores","text":"","title":"sentiment_scores"},{"location":"reference/helpers/sentiment_scores/#pxtextmining.helpers.sentiment_scores.sentiment_scores","text":"Calculate sentiment indicators from TextBlob <https://textblob.readthedocs.io/en/dev/> (polarity and subjectivity) and vaderSentiment <https://pypi.org/project/vaderSentiment/> (positive, negative and neutral sentiments and compound score). Parameters: Name Type Description Default X pd.DataFrame A dictionary, pandas.DataFrame , tuple or list with the text strings. If it is a dictionary, it must have a single key (column). required Returns: Type Description pd.DataFrame A pandas.DataFrame with the sentiment scores for each text record. Shape [n_samples, 6]. Source code in pxtextmining/helpers/sentiment_scores.py def sentiment_scores(X): \"\"\" Calculate sentiment indicators from `TextBlob <https://textblob.readthedocs.io/en/dev/>`_ (polarity and subjectivity) and `vaderSentiment <https://pypi.org/project/vaderSentiment/>`_ (positive, negative and neutral sentiments and compound score). :param pd.DataFrame X: A dictionary, ``pandas.DataFrame``, tuple or list with the text strings. If it is a dictionary, it must have a single key (column). :return: A ``pandas.DataFrame`` with the sentiment scores for each text record. Shape [n_samples, 6]. :rtype: pd.DataFrame \"\"\" vader_analyser = SentimentIntensityAnalyzer() X = pd.DataFrame(X).copy().rename(lambda x: 'predictor', axis='columns') text_blob_scores = [] vader_scores = [] for i in X.index: text = X.loc[i, 'predictor'] if text is None or str(text) == 'nan': text = '' text_blob_scores.append(TextBlob(text).sentiment) vader_scores.append(vader_analyser.polarity_scores(text)) text_blob_scores_df = pd.DataFrame(text_blob_scores) text_blob_scores_df.columns = 'text_blob_' + text_blob_scores_df.columns text_blob_scores_df.index = X.index vader_scores_df = pd.DataFrame.from_dict(vader_scores) vader_scores_df.columns = 'vader_' + vader_scores_df.columns vader_scores_df.index = X.index all_scores = pd.concat([text_blob_scores_df, vader_scores_df], axis=1, ignore_index=False) return all_scores","title":"sentiment_scores()"},{"location":"reference/helpers/text_length/","text":"text_length text_length(X) Calculate the length of a given text. Parameters: Name Type Description Default X pd.DataFrame A dictionary, pandas.DataFrame , tuple or list with the text strings. If it is a dictionary ( pandas.DataFrame ), it must have a single key (column). required Returns: Type Description pd.DataFrame A pandas.DataFrame with the length of each text record. Shape [n_samples, 1]. Source code in pxtextmining/helpers/text_length.py def text_length(X): \"\"\" Calculate the length of a given text. :param pd.DataFrame X: A dictionary, ``pandas.DataFrame``, tuple or list with the text strings. If it is a dictionary (``pandas.DataFrame``), it must have a single key (column). :return: A ``pandas.DataFrame`` with the length of each text record. Shape [n_samples, 1]. :rtype: pd.DataFrame \"\"\" X = pd.DataFrame(X).copy().rename(lambda x: 'predictor', axis='columns') text_length = [] for i in X.index: text = X.loc[i, 'predictor'] if text is None or str(text) == 'nan': text_length.append(len('')) else: text_length.append(len(text)) text_length_df = pd.DataFrame(text_length) text_length_df.columns = ['text_length'] text_length_df.index = X.index return text_length_df","title":"Text length"},{"location":"reference/helpers/text_length/#pxtextmining.helpers.text_length","text":"","title":"text_length"},{"location":"reference/helpers/text_length/#pxtextmining.helpers.text_length.text_length","text":"Calculate the length of a given text. Parameters: Name Type Description Default X pd.DataFrame A dictionary, pandas.DataFrame , tuple or list with the text strings. If it is a dictionary ( pandas.DataFrame ), it must have a single key (column). required Returns: Type Description pd.DataFrame A pandas.DataFrame with the length of each text record. Shape [n_samples, 1]. Source code in pxtextmining/helpers/text_length.py def text_length(X): \"\"\" Calculate the length of a given text. :param pd.DataFrame X: A dictionary, ``pandas.DataFrame``, tuple or list with the text strings. If it is a dictionary (``pandas.DataFrame``), it must have a single key (column). :return: A ``pandas.DataFrame`` with the length of each text record. Shape [n_samples, 1]. :rtype: pd.DataFrame \"\"\" X = pd.DataFrame(X).copy().rename(lambda x: 'predictor', axis='columns') text_length = [] for i in X.index: text = X.loc[i, 'predictor'] if text is None or str(text) == 'nan': text_length.append(len('')) else: text_length.append(len(text)) text_length_df = pd.DataFrame(text_length) text_length_df.columns = ['text_length'] text_length_df.index = X.index return text_length_df","title":"text_length()"},{"location":"reference/helpers/text_preprocessor/","text":"text_preprocessor text_preprocessor(text_string) Strips punctuation, excess spaces, and metacharacters \"r\" and \"n\" from the text. Converts emojis into \" text \" (where \"text\" is the emoji name) and any NAs resulting from text preprocessing into \" notext \". Parameters: Name Type Description Default text_string str Text string that is passed from sklearn.feature_extraction.text.TfidfVectorizer required Returns: Type Description str text_string : Cleaned text string. Source code in pxtextmining/helpers/text_preprocessor.py def text_preprocessor(text_string): \"\"\" Strips punctuation, excess spaces, and metacharacters \"r\" and \"n\" from the text. Converts emojis into \"__text__\" (where \"text\" is the emoji name) and any NAs resulting from text preprocessing into \"__notext__\". :param str text_string: Text string that is passed from [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) :return: text_string : Cleaned text string. :rtype: str \"\"\" text_string = str(text_string) text_string = emojis.decode(text_string) pattern = \"\\:(.*?)\\:\" # Decoded emojis are enclosed inside \":\", e.g. \":blush:\" pattern_search = re.search(pattern, text_string) # We want to tell the model that words inside \":\" are decoded emojis. # However, \"[^\\w]\" removes \":\". It doesn't remove \"_\" or \"__\" though, so we may enclose decoded emojis # inside \"__\" instead. if pattern_search is not None: emoji_decoded = pattern_search.group(1) \"\"\"if keep_emojis: text_string = re.sub(pattern, \"__\" + emoji_decoded + \"__\", text_string) # Sometimes emojis are consecutive e.g. \u2764\u2764 is encoded into __heart____heart__. Split them. text_string = re.sub(\"____\", \"__ __\", text_string) else: text_string = re.sub(pattern, \"\", text_string)\"\"\" text_string = re.sub(pattern, \"__\" + emoji_decoded + \"__\", text_string) # Sometimes emojis are consecutive e.g. \u2764\u2764 is encoded into __heart____heart__. Split them. text_string = re.sub(\"____\", \"__ __\", text_string) # Remove non-alphanumeric characters text_string = re.sub(\"[^\\w]\", \" \", text_string) # Remove excess whitespaces text_string = re.sub(\" +\", \" \", text_string) text_string = text_string.rstrip() # Removes trailing spaces. # text_string = \" \".join(text.splitlines()) if str(text_string) in (\"nan\", \"None\", \" \"): text_string = \"__notext__\" return text_string","title":"Text preprocessor"},{"location":"reference/helpers/text_preprocessor/#pxtextmining.helpers.text_preprocessor","text":"","title":"text_preprocessor"},{"location":"reference/helpers/text_preprocessor/#pxtextmining.helpers.text_preprocessor.text_preprocessor","text":"Strips punctuation, excess spaces, and metacharacters \"r\" and \"n\" from the text. Converts emojis into \" text \" (where \"text\" is the emoji name) and any NAs resulting from text preprocessing into \" notext \". Parameters: Name Type Description Default text_string str Text string that is passed from sklearn.feature_extraction.text.TfidfVectorizer required Returns: Type Description str text_string : Cleaned text string. Source code in pxtextmining/helpers/text_preprocessor.py def text_preprocessor(text_string): \"\"\" Strips punctuation, excess spaces, and metacharacters \"r\" and \"n\" from the text. Converts emojis into \"__text__\" (where \"text\" is the emoji name) and any NAs resulting from text preprocessing into \"__notext__\". :param str text_string: Text string that is passed from [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) :return: text_string : Cleaned text string. :rtype: str \"\"\" text_string = str(text_string) text_string = emojis.decode(text_string) pattern = \"\\:(.*?)\\:\" # Decoded emojis are enclosed inside \":\", e.g. \":blush:\" pattern_search = re.search(pattern, text_string) # We want to tell the model that words inside \":\" are decoded emojis. # However, \"[^\\w]\" removes \":\". It doesn't remove \"_\" or \"__\" though, so we may enclose decoded emojis # inside \"__\" instead. if pattern_search is not None: emoji_decoded = pattern_search.group(1) \"\"\"if keep_emojis: text_string = re.sub(pattern, \"__\" + emoji_decoded + \"__\", text_string) # Sometimes emojis are consecutive e.g. \u2764\u2764 is encoded into __heart____heart__. Split them. text_string = re.sub(\"____\", \"__ __\", text_string) else: text_string = re.sub(pattern, \"\", text_string)\"\"\" text_string = re.sub(pattern, \"__\" + emoji_decoded + \"__\", text_string) # Sometimes emojis are consecutive e.g. \u2764\u2764 is encoded into __heart____heart__. Split them. text_string = re.sub(\"____\", \"__ __\", text_string) # Remove non-alphanumeric characters text_string = re.sub(\"[^\\w]\", \" \", text_string) # Remove excess whitespaces text_string = re.sub(\" +\", \" \", text_string) text_string = text_string.rstrip() # Removes trailing spaces. # text_string = \" \".join(text.splitlines()) if str(text_string) in (\"nan\", \"None\", \" \"): text_string = \"__notext__\" return text_string","title":"text_preprocessor()"},{"location":"reference/helpers/text_transformer_switcher/","text":"text_transformer_switcher TextTransformerSwitcher Bases: BaseEstimator , TransformerMixin Class for choosing between Bag-of-Words and embeddings transformers in Randomized Search. Source code in pxtextmining/helpers/text_transformer_switcher.py class TextTransformerSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for choosing between Bag-of-Words and embeddings transformers in Randomized Search. \"\"\" def __init__(self, transformer=TfidfVectorizer()): self.transformer = transformer def fit(self, X, y=None, **kwargs): self.transformer.fit(X) return self def transform(self, X, y=None, **kwargs): return self.transformer.transform(X) transformer = transformer instance-attribute __init__(transformer=TfidfVectorizer()) Source code in pxtextmining/helpers/text_transformer_switcher.py def __init__(self, transformer=TfidfVectorizer()): self.transformer = transformer fit(X, y=None, **kwargs) Source code in pxtextmining/helpers/text_transformer_switcher.py def fit(self, X, y=None, **kwargs): self.transformer.fit(X) return self transform(X, y=None, **kwargs) Source code in pxtextmining/helpers/text_transformer_switcher.py def transform(self, X, y=None, **kwargs): return self.transformer.transform(X)","title":"Text transformer switcher"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher","text":"","title":"text_transformer_switcher"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher.TextTransformerSwitcher","text":"Bases: BaseEstimator , TransformerMixin Class for choosing between Bag-of-Words and embeddings transformers in Randomized Search. Source code in pxtextmining/helpers/text_transformer_switcher.py class TextTransformerSwitcher(BaseEstimator, TransformerMixin): \"\"\" Class for choosing between Bag-of-Words and embeddings transformers in Randomized Search. \"\"\" def __init__(self, transformer=TfidfVectorizer()): self.transformer = transformer def fit(self, X, y=None, **kwargs): self.transformer.fit(X) return self def transform(self, X, y=None, **kwargs): return self.transformer.transform(X)","title":"TextTransformerSwitcher"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher.TextTransformerSwitcher.transformer","text":"","title":"transformer"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher.TextTransformerSwitcher.__init__","text":"Source code in pxtextmining/helpers/text_transformer_switcher.py def __init__(self, transformer=TfidfVectorizer()): self.transformer = transformer","title":"__init__()"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher.TextTransformerSwitcher.fit","text":"Source code in pxtextmining/helpers/text_transformer_switcher.py def fit(self, X, y=None, **kwargs): self.transformer.fit(X) return self","title":"fit()"},{"location":"reference/helpers/text_transformer_switcher/#pxtextmining.helpers.text_transformer_switcher.TextTransformerSwitcher.transform","text":"Source code in pxtextmining/helpers/text_transformer_switcher.py def transform(self, X, y=None, **kwargs): return self.transformer.transform(X)","title":"transform()"},{"location":"reference/helpers/theme_binarization/","text":"theme_binarization ThemeBinarizer Bases: BaseEstimator , TransformerMixin Class for binarizing categories. Sets a selected category to 1 and the rest to 0. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default class_col str The name of the column with the classes to binarize. None target_class str_or_int The name (if a string) or value (if numeric) of the class that will be set to set_class_to . None set_class_to int The value to set the target_class to. Defaults to 1. 1 set_rest_to int The value to set all classes but target_class to. Defaults to 0. 0 Source code in pxtextmining/helpers/theme_binarization.py class ThemeBinarizer(BaseEstimator, TransformerMixin): \"\"\" Class for binarizing categories. Sets a selected category to 1 and the rest to 0. **NOTE:** As described later, argument `theme` is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. :param str class_col: The name of the column with the classes to binarize. :param str_or_int target_class: The name (if a string) or value (if numeric) of the class that will be set to `set_class_to`. :param int set_class_to: The value to set the `target_class` to. Defaults to 1. :param int set_rest_to: The value to set all classes but `target_class` to. Defaults to 0. \"\"\" def __init__(self, class_col=None, target_class=None, set_class_to=1, set_rest_to=0): self.class_col = class_col self.target_class = target_class self.set_class_to = set_class_to self.set_rest_to = set_rest_to def fit(self, X, y=None): return self def transform(self, X): X.loc[X[self.class_col] == self.target_class, self.class_col] = self.set_class_to # Seems like it's okay to have some rows with numbers and some with strings X.loc[X[self.class_col] != self.set_class_to, self.class_col] = self.set_rest_to # X[self.class_col] = X[self.class_col].apply(pd.to_numeric, errors='coerce', downcast='integer').copy() return X class_col = class_col instance-attribute target_class = target_class instance-attribute set_class_to = set_class_to instance-attribute set_rest_to = set_rest_to instance-attribute __init__(class_col=None, target_class=None, set_class_to=1, set_rest_to=0) Source code in pxtextmining/helpers/theme_binarization.py def __init__(self, class_col=None, target_class=None, set_class_to=1, set_rest_to=0): self.class_col = class_col self.target_class = target_class self.set_class_to = set_class_to self.set_rest_to = set_rest_to fit(X, y=None) Source code in pxtextmining/helpers/theme_binarization.py def fit(self, X, y=None): return self transform(X) Source code in pxtextmining/helpers/theme_binarization.py def transform(self, X): X.loc[X[self.class_col] == self.target_class, self.class_col] = self.set_class_to # Seems like it's okay to have some rows with numbers and some with strings X.loc[X[self.class_col] != self.set_class_to, self.class_col] = self.set_rest_to # X[self.class_col] = X[self.class_col].apply(pd.to_numeric, errors='coerce', downcast='integer').copy() return X","title":"Theme binarization"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization","text":"","title":"theme_binarization"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer","text":"Bases: BaseEstimator , TransformerMixin Class for binarizing categories. Sets a selected category to 1 and the rest to 0. NOTE: As described later, argument theme is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. Parameters: Name Type Description Default class_col str The name of the column with the classes to binarize. None target_class str_or_int The name (if a string) or value (if numeric) of the class that will be set to set_class_to . None set_class_to int The value to set the target_class to. Defaults to 1. 1 set_rest_to int The value to set all classes but target_class to. Defaults to 0. 0 Source code in pxtextmining/helpers/theme_binarization.py class ThemeBinarizer(BaseEstimator, TransformerMixin): \"\"\" Class for binarizing categories. Sets a selected category to 1 and the rest to 0. **NOTE:** As described later, argument `theme` is for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) labels. It can otherwise be safely ignored. :param str class_col: The name of the column with the classes to binarize. :param str_or_int target_class: The name (if a string) or value (if numeric) of the class that will be set to `set_class_to`. :param int set_class_to: The value to set the `target_class` to. Defaults to 1. :param int set_rest_to: The value to set all classes but `target_class` to. Defaults to 0. \"\"\" def __init__(self, class_col=None, target_class=None, set_class_to=1, set_rest_to=0): self.class_col = class_col self.target_class = target_class self.set_class_to = set_class_to self.set_rest_to = set_rest_to def fit(self, X, y=None): return self def transform(self, X): X.loc[X[self.class_col] == self.target_class, self.class_col] = self.set_class_to # Seems like it's okay to have some rows with numbers and some with strings X.loc[X[self.class_col] != self.set_class_to, self.class_col] = self.set_rest_to # X[self.class_col] = X[self.class_col].apply(pd.to_numeric, errors='coerce', downcast='integer').copy() return X","title":"ThemeBinarizer"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.class_col","text":"","title":"class_col"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.target_class","text":"","title":"target_class"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.set_class_to","text":"","title":"set_class_to"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.set_rest_to","text":"","title":"set_rest_to"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.__init__","text":"Source code in pxtextmining/helpers/theme_binarization.py def __init__(self, class_col=None, target_class=None, set_class_to=1, set_rest_to=0): self.class_col = class_col self.target_class = target_class self.set_class_to = set_class_to self.set_rest_to = set_rest_to","title":"__init__()"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.fit","text":"Source code in pxtextmining/helpers/theme_binarization.py def fit(self, X, y=None): return self","title":"fit()"},{"location":"reference/helpers/theme_binarization/#pxtextmining.helpers.theme_binarization.ThemeBinarizer.transform","text":"Source code in pxtextmining/helpers/theme_binarization.py def transform(self, X): X.loc[X[self.class_col] == self.target_class, self.class_col] = self.set_class_to # Seems like it's okay to have some rows with numbers and some with strings X.loc[X[self.class_col] != self.set_class_to, self.class_col] = self.set_rest_to # X[self.class_col] = X[self.class_col].apply(pd.to_numeric, errors='coerce', downcast='integer').copy() return X","title":"transform()"},{"location":"reference/helpers/tokenization/","text":"tokenization nlp = spacy.load('en_core_web_sm') module-attribute LemmaTokenizer Class for custom lemmatization in sklearn.feature_extraction.text.TfidfVectorizer (see this ). Uses spaCy ( tknz == 'spacy' ) or NLTK ( tknz == 'wordnet' ). Source code in pxtextmining/helpers/tokenization.py class LemmaTokenizer: \"\"\" Class for custom lemmatization in [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) (see [this](https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=stemming)). Uses [spaCy](https://spacy.io/) (``tknz == 'spacy'``) or [NLTK](https://www.nltk.org/) (``tknz == 'wordnet'``). \"\"\" def __init__(self, tknz='wordnet'): self.tknz = tknz def __call__(self, doc): if self.tknz == 'wordnet': wln = WordNetLemmatizer() return [wln.lemmatize(t) for t in word_tokenize(doc)] if self.tknz == 'spacy': return [t.lemma_ for t in nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"])] tknz = tknz instance-attribute __init__(tknz='wordnet') Source code in pxtextmining/helpers/tokenization.py def __init__(self, tknz='wordnet'): self.tknz = tknz __call__(doc) Source code in pxtextmining/helpers/tokenization.py def __call__(self, doc): if self.tknz == 'wordnet': wln = WordNetLemmatizer() return [wln.lemmatize(t) for t in word_tokenize(doc)] if self.tknz == 'spacy': return [t.lemma_ for t in nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"])]","title":"Tokenization"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization","text":"","title":"tokenization"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization.nlp","text":"","title":"nlp"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization.LemmaTokenizer","text":"Class for custom lemmatization in sklearn.feature_extraction.text.TfidfVectorizer (see this ). Uses spaCy ( tknz == 'spacy' ) or NLTK ( tknz == 'wordnet' ). Source code in pxtextmining/helpers/tokenization.py class LemmaTokenizer: \"\"\" Class for custom lemmatization in [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) (see [this](https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=stemming)). Uses [spaCy](https://spacy.io/) (``tknz == 'spacy'``) or [NLTK](https://www.nltk.org/) (``tknz == 'wordnet'``). \"\"\" def __init__(self, tknz='wordnet'): self.tknz = tknz def __call__(self, doc): if self.tknz == 'wordnet': wln = WordNetLemmatizer() return [wln.lemmatize(t) for t in word_tokenize(doc)] if self.tknz == 'spacy': return [t.lemma_ for t in nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"])]","title":"LemmaTokenizer"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization.LemmaTokenizer.tknz","text":"","title":"tknz"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization.LemmaTokenizer.__init__","text":"Source code in pxtextmining/helpers/tokenization.py def __init__(self, tknz='wordnet'): self.tknz = tknz","title":"__init__()"},{"location":"reference/helpers/tokenization/#pxtextmining.helpers.tokenization.LemmaTokenizer.__call__","text":"Source code in pxtextmining/helpers/tokenization.py def __call__(self, doc): if self.tknz == 'wordnet': wln = WordNetLemmatizer() return [wln.lemmatize(t) for t in word_tokenize(doc)] if self.tknz == 'spacy': return [t.lemma_ for t in nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"])]","title":"__call__()"},{"location":"reference/helpers/word_vectorization/","text":"word_vectorization nlp = spacy.load('en_core_web_lg') module-attribute EmbeddingsTransformer Bases: TransformerMixin , BaseEstimator Class for converting text into GloVe word vectors with spaCy . Helpful resource here . Source code in pxtextmining/helpers/word_vectorization.py class EmbeddingsTransformer(TransformerMixin, BaseEstimator): \"\"\" Class for converting text into [GloVe](https://nlp.stanford.edu/projects/glove/) word vectors with [spaCy](https://spacy.io/). Helpful resource [here](https://lvngd.com/blog/spacy-word-vectors-as-features-in-scikit-learn/). \"\"\" def __init__(self, model=None): self.model = model def fit(self, X, y=None): return self def transform(self, X): X_processed = [text_preprocessor(doc) for doc in X] return np.concatenate([nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"]).vector.reshape(1, -1) for doc in X_processed]) model = model instance-attribute __init__(model=None) Source code in pxtextmining/helpers/word_vectorization.py def __init__(self, model=None): self.model = model fit(X, y=None) Source code in pxtextmining/helpers/word_vectorization.py def fit(self, X, y=None): return self transform(X) Source code in pxtextmining/helpers/word_vectorization.py def transform(self, X): X_processed = [text_preprocessor(doc) for doc in X] return np.concatenate([nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"]).vector.reshape(1, -1) for doc in X_processed])","title":"Word vectorization"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization","text":"","title":"word_vectorization"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.nlp","text":"","title":"nlp"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.EmbeddingsTransformer","text":"Bases: TransformerMixin , BaseEstimator Class for converting text into GloVe word vectors with spaCy . Helpful resource here . Source code in pxtextmining/helpers/word_vectorization.py class EmbeddingsTransformer(TransformerMixin, BaseEstimator): \"\"\" Class for converting text into [GloVe](https://nlp.stanford.edu/projects/glove/) word vectors with [spaCy](https://spacy.io/). Helpful resource [here](https://lvngd.com/blog/spacy-word-vectors-as-features-in-scikit-learn/). \"\"\" def __init__(self, model=None): self.model = model def fit(self, X, y=None): return self def transform(self, X): X_processed = [text_preprocessor(doc) for doc in X] return np.concatenate([nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"]).vector.reshape(1, -1) for doc in X_processed])","title":"EmbeddingsTransformer"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.EmbeddingsTransformer.model","text":"","title":"model"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.EmbeddingsTransformer.__init__","text":"Source code in pxtextmining/helpers/word_vectorization.py def __init__(self, model=None): self.model = model","title":"__init__()"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.EmbeddingsTransformer.fit","text":"Source code in pxtextmining/helpers/word_vectorization.py def fit(self, X, y=None): return self","title":"fit()"},{"location":"reference/helpers/word_vectorization/#pxtextmining.helpers.word_vectorization.EmbeddingsTransformer.transform","text":"Source code in pxtextmining/helpers/word_vectorization.py def transform(self, X): X_processed = [text_preprocessor(doc) for doc in X] return np.concatenate([nlp(doc, disable=[\"tagger\", \"parser\", \"ner\"]).vector.reshape(1, -1) for doc in X_processed])","title":"transform()"},{"location":"reference/pipelines/text_classification_pipeline/","text":"text_classification_pipeline text_classification_pipeline(filename, target, predictor, test_size=0.33, ordinal=False, tknz='spacy', metric='class_balance_accuracy_score', cv=5, n_iter=100, n_jobs=5, verbose=3, learners=['SGDClassifier'], objects_to_save=['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'], save_objects_to_server=True, save_objects_to_disk=False, save_pipeline_as='default', results_folder_name='results', reduce_criticality=True, theme=None) Function that gathers together all steps in Factories module to train a new model pipeline and write the results. Writes between 1 to 7 files, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG); NOTE: As described later, arguments reduce_criticality and theme are for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) and criticality labels. They can otherwise be safely ignored. Parameters: Name Type Description Default filename str Dataset name (CSV), including the data type suffix. If None, data is read from the database. required target str Name of the response variable. required predictor str Name of the predictor variable. required test_size float Proportion of data that will form the test dataset. 0.33 ordinal bool Whether to fit an ordinal classification model. The ordinal model is the implementation of Frank and Hall (2001) <https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf> _ that can use any standard classification model. False tknz str Tokenizer to use (\"spacy\" or \"wordnet\"). 'spacy' metric str Scorer to use during pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' cv int Number of cross-validation folds. 5 n_iter int Number of parameter settings that are sampled (see sklearn.model_selection.RandomizedSearchCV <https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html> _). 100 n_jobs int Number of jobs to run in parallel (see sklearn.model_selection.RandomizedSearchCV ). 5 verbose int Controls the verbosity (see sklearn.model_selection.RandomizedSearchCV ). 3 learners list[str] A list of Scikit-learn names of the learners to tune. Must be one or more of \"SGDClassifier\", \"RidgeClassifier\", \"Perceptron\", \"PassiveAggressiveClassifier\", \"BernoulliNB\", \"ComplementNB\", \"MultinomialNB\", \"KNeighborsClassifier\", \"NearestCentroid\", \"RandomForestClassifier\". ['SGDClassifier'] objects_to_save list[str] Objects to save following pipeline fitting and assessment. These are: - the pipeline (SAV file); - table with all (hyper)parameter values tried out and performance indicators on the cross-validation data; - table with predictions on the test set; - table with accuracy and counts per class; - row indices for the training set; - row indices for the test set; - bar plot with the best-performing models- plotted values are the mean scores from a k-fold CV on the training set, for the best (hyper)parameter values for each learner; ['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'] save_objects_to_server bool Whether to save the results to the server. NOTE: The feature that writes results to the database is for internal use only. It will be removed when a proper API is developed for this function. True save_objects_to_disk bool Whether to save the results to disk. See results_folder_name . False save_pipeline_as str Save the pipeline as save_pipeline_as + '.sav' . 'default' results_folder_name str Name of folder in which to save the results. It will create a new folder or overwrite an existing one that has the same name. 'results' reduce_criticality bool For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that hold data on criticality. If True , then all records with a criticality of \"-5\" (respectively, \"5\") are assigned a criticality of \"-4\" (respectively, \"4\"). This is to avoid situations where the pipeline breaks due to a lack of sufficient data for \"-5\" and/or \"5\". Defaults to False . True theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description tuple A tuple of variable length depending on 'objects_to_save' parameter. It can contain any of the following objects, in order: - The fitted Scikit-learn / imblearn pipeline; - A pandas.DataFrame with all (hyper)parameter values and models tried during fitting; - A pandas.DataFrame with the predictions on the test set; - A pandas.DataFrame with accuracies per class; - A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner. - The row indices of the training data; - The row indices of the test data","title":"Text classification pipeline"},{"location":"reference/pipelines/text_classification_pipeline/#pxtextmining.pipelines.text_classification_pipeline","text":"","title":"text_classification_pipeline"},{"location":"reference/pipelines/text_classification_pipeline/#pxtextmining.pipelines.text_classification_pipeline.text_classification_pipeline","text":"Function that gathers together all steps in Factories module to train a new model pipeline and write the results. Writes between 1 to 7 files, depending on the value of argument objects_to_save : The fitted pipeline (SAV); All (hyper)parameters tried during fitting and the associated pipeline performance metrics (CSV); The predictions on the test set (CSV); Accuracies per class (CSV); The row indices of the training data (CSV); The row indices of the test data (CSV); A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner (PNG); NOTE: As described later, arguments reduce_criticality and theme are for internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts who use the theme (\"Access\", \"Environment/ facilities\" etc.) and criticality labels. They can otherwise be safely ignored. Parameters: Name Type Description Default filename str Dataset name (CSV), including the data type suffix. If None, data is read from the database. required target str Name of the response variable. required predictor str Name of the predictor variable. required test_size float Proportion of data that will form the test dataset. 0.33 ordinal bool Whether to fit an ordinal classification model. The ordinal model is the implementation of Frank and Hall (2001) <https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf> _ that can use any standard classification model. False tknz str Tokenizer to use (\"spacy\" or \"wordnet\"). 'spacy' metric str Scorer to use during pipeline tuning (\"accuracy_score\", \"balanced_accuracy_score\", \"matthews_corrcoef\", \"class_balance_accuracy_score\"). 'class_balance_accuracy_score' cv int Number of cross-validation folds. 5 n_iter int Number of parameter settings that are sampled (see sklearn.model_selection.RandomizedSearchCV <https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html> _). 100 n_jobs int Number of jobs to run in parallel (see sklearn.model_selection.RandomizedSearchCV ). 5 verbose int Controls the verbosity (see sklearn.model_selection.RandomizedSearchCV ). 3 learners list[str] A list of Scikit-learn names of the learners to tune. Must be one or more of \"SGDClassifier\", \"RidgeClassifier\", \"Perceptron\", \"PassiveAggressiveClassifier\", \"BernoulliNB\", \"ComplementNB\", \"MultinomialNB\", \"KNeighborsClassifier\", \"NearestCentroid\", \"RandomForestClassifier\". ['SGDClassifier'] objects_to_save list[str] Objects to save following pipeline fitting and assessment. These are: - the pipeline (SAV file); - table with all (hyper)parameter values tried out and performance indicators on the cross-validation data; - table with predictions on the test set; - table with accuracy and counts per class; - row indices for the training set; - row indices for the test set; - bar plot with the best-performing models- plotted values are the mean scores from a k-fold CV on the training set, for the best (hyper)parameter values for each learner; ['pipeline', 'tuning results', 'predictions', 'accuracy per class', 'index - training data', 'index - test data', 'bar plot'] save_objects_to_server bool Whether to save the results to the server. NOTE: The feature that writes results to the database is for internal use only. It will be removed when a proper API is developed for this function. True save_objects_to_disk bool Whether to save the results to disk. See results_folder_name . False save_pipeline_as str Save the pipeline as save_pipeline_as + '.sav' . 'default' results_folder_name str Name of folder in which to save the results. It will create a new folder or overwrite an existing one that has the same name. 'results' reduce_criticality bool For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that hold data on criticality. If True , then all records with a criticality of \"-5\" (respectively, \"5\") are assigned a criticality of \"-4\" (respectively, \"4\"). This is to avoid situations where the pipeline breaks due to a lack of sufficient data for \"-5\" and/or \"5\". Defaults to False . True theme str For internal use by Nottinghamshire Healthcare NHS Foundation Trust or other trusts that use theme labels (\"Access\", \"Environment/ facilities\" etc.). The column name of the theme variable. Defaults to None . If supplied, the theme variable will be used as a predictor (along with the text predictor) in the model that is fitted with criticality as the response variable. The rationale is two-fold. First, to help the model improve predictions on criticality when the theme labels are readily available. Second, to force the criticality for \"Couldn't be improved\" to always be \"3\" in the training and test data, as well as in the predictions. This is the only criticality value that \"Couldn't be improved\" can take, so by forcing it to always be \"3\", we are improving model performance, but are also correcting possible erroneous assignments of values other than \"3\" that are attributed to human error. None Returns: Type Description tuple A tuple of variable length depending on 'objects_to_save' parameter. It can contain any of the following objects, in order: - The fitted Scikit-learn / imblearn pipeline; - A pandas.DataFrame with all (hyper)parameter values and models tried during fitting; - A pandas.DataFrame with the predictions on the test set; - A pandas.DataFrame with accuracies per class; - A bar plot comparing the mean scores (of the user-supplied metric parameter) from the cross-validation on the training set, for the best (hyper)parameter values for each learner. - The row indices of the training data; - The row indices of the test data","title":"text_classification_pipeline()"}]}